{"Major": "Statistics", "Term": "mutual independence", "Explanation": "- Basic idea in one sentence: Mutual independence means the outcome of one event doesn’t change the chances of any other events, even when you look at all of them together.\n\n- Real-world example (1–2 sentences): Flip three fair coins. The chance all three are heads is 1/8, which is (1/2)×(1/2)×(1/2). Knowing the first flip is heads doesn’t change the odds for the other two flips.\n\n- Why it matters, quick takeaway: If a group of events is mutually independent, you can multiply their individual probabilities to get the chance of a combined outcome; if they aren’t, you can’t just multiply and need to account for how they affect each other."}
{"Major": "Statistics", "Term": "statistical inference", "Explanation": "- Basic idea: Statistical inference is like tasting a spoonful of soup to guess the flavor of the whole pot: we use clues from a small sample to guess about a larger group.\n- Real-world example: Polls survey 1,000 people in a city to guess how the roughly 1 million voters will vote. From that sample, we estimate the overall city preference and note the margin of error.\n- Takeaway: It helps us learn about the world without counting everyone, but results are not exact and come with uncertainty."}
{"Major": "Statistics", "Term": "joint distribution", "Explanation": "- Basic idea: A joint distribution is a way to describe how likely different combinations of two or more random things are to occur together.\n\n- Real-world example: Imagine rolling two fair dice. The joint distribution lists the probability for each ordered pair (1,1) through (6,6). From it you can see the chance the dice match (6 out of 36) and you can compute the odds of any particular sum.\n\n- Why it matters: It helps us understand how things relate, not just their individual chances, so we can make better predictions and decisions when two things influence each other. If the variables are independent, the joint chances are simply the product of their separate chances."}
{"Major": "Statistics", "Term": "random variable", "Explanation": "- Basic idea: A random variable is a rule that assigns a number to every possible outcome of a random event.\n\n- Real-world example: Roll a six-sided die. The random variable X could be the face value that comes up (1–6). For a coin flip, X could be 1 for heads and 0 for tails.\n\n- Why it matters: It lets us study randomness with numbers—like the average outcome and how much outcomes vary—without listing every result. Takeaway: random variables turn unpredictable results into a single, analyzable number story."}
{"Major": "Statistics", "Term": "confidence interval (CI)", "Explanation": "- Basic idea in one sentence: A confidence interval is a range of numbers that we think likely contains the true value we’re estimating, based on the data we collected. (CI)\n\n- Real-world example (1–2 sentences): After surveying 50 students about daily study time, you might report: “We’re 95% confident the true average study time is between 3.5 and 4.5 hours per day.” This means the method would give a correct range about 95% of the time if repeated many times.\n\n- Why it matters with a quick takeaway: It shows both an estimate and how sure we are about it, so we report not just a single number but a plausible range for the true value. Takeaway: use a confidence interval to convey uncertainty, not just a single guess."}
{"Major": "Statistics", "Term": "covariance", "Explanation": "- Covariance is a measure of how two quantities move together—whether they tend to rise and fall together, fall apart, or show no consistent pattern.\n\n- Example: Students who study more hours usually score higher on exams. Another everyday example is that on hot days, ice cream sales tend to rise along with sunscreen sales—both go up together.\n\n- Takeaway: Covariance helps you see if two things move in tandem, but its size depends on the units you use, so we often convert it to correlation to compare different pairs."}
{"Major": "Statistics", "Term": "likelihood function", "Explanation": "- The basic idea (one sentence, with a simple analogy): The likelihood function asks, for each possible value of a parameter, how likely the observed data would be if that value were true—like trying different keys on a lock to see which fits best.\n\n- Real-world example (1–2 sentences): Example: you suspect a coin is biased. After 10 flips you get 7 heads. The likelihood is higher for bias values near 0.7 than near 0.5, because 7 heads is more probable if the bias is around 0.7.\n\n- Why it matters (quick takeaway): Likelihood helps us pick the parameter value that makes our data most probable (maximum likelihood) and compare different models."}
{"Major": "Statistics", "Term": "probability measure", "Explanation": "- Basic idea: A probability measure is a rule that assigns a number between 0 and 1 to each possible event, representing how likely it is, with all outcomes together summing to 1.\n- Real-world example: For a fair six-sided die, each face has probability 1/6; the event “even number” has probability 2/6; and the probabilities of all outcomes add up to 1.\n- Why it matters (takeaway): This gives a consistent way to quantify chances, so we can compare results, make predictions, and reason about uncertainty in everyday decisions."}
{"Major": "Statistics", "Term": "regression analysis", "Explanation": "- Basic idea: Regression analysis is like drawing the best-fit line through a scatter of dots to show how one thing tends to change with another. \n- Real-world example: For study hours versus exam scores, it can show whether more hours are linked to higher scores and give a rough amount you might expect per extra hour. \n- Why it matters: Takeaway: it helps you predict outcomes from data and understand relationships, but it doesn’t prove cause and effect."}
{"Major": "Statistics", "Term": "causal study", "Explanation": "- Basic idea: A causal study asks whether changing one thing (the cause) will lead to a change in another thing (the effect).\n\n- Real-world example: If a school adds tutoring time to raise grades, and test scores go up after, the study suggests tutoring caused the improvement. Analogy: it’s like watering a plant to see if it grows taller.\n\n- Why it matters: It helps us know what actions will actually change outcomes, not just notice that two things happen together. Quick takeaway: causal studies test what happens if we do X."}
