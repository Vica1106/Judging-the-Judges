{"Major": "Computer Science", "Term": "quantum computing", "Explanation": "- 1) Basic idea: Quantum computing uses the strange rules of quantum physics to process information in a way that can explore many possibilities at once, potentially solving certain problems much faster than ordinary computers.\n\n- 2) Analogy and real-world example: Analogy: it’s like a librarian who can check many shelves at the same time and guide you to the right book. Real-world example: in fields like drug design or route optimization, there are huge sets of possibilities; a quantum computer could explore those options more efficiently and point toward promising solutions.\n\n- 3) Takeaway: It won’t replace everyday computers yet, but it could unlock powerful new capabilities for science, medicine, and security in the future."}
{"Major": "Computer Science", "Term": "big O notation", "Explanation": "- Basic idea: Big O is a simple way to say how the amount of work a program does grows as the amount of data grows.\n- Real-world example: Analogy: it’s like searching for a name in an unorganized phone book—you might flip through many pages, and as the book gets bigger, the number of pages you flip grows roughly in proportion.\n- Why it matters (takeaway): It helps you predict how a program will slow down as data grows and choose faster methods, since small differences in growth rate become big as data gets larger."}
{"Major": "Computer Science", "Term": "semantics", "Explanation": "- (1) Basic idea: Semantics is the meaning or effect of code—what the program actually does when it runs, not just how it’s written.\n\n- (2) Real-world example: Example: x = 2 + 3 makes x equal to 5, and if (x > 0) then print('hi') will run. Think of semantics like the final dish from a recipe—the same steps (syntax) should produce the same result (the dish) even if wording changes.\n\n- (3) Why it matters (quick takeaway): Semantics helps you predict behavior, verify that code does what you expect, and compare different programming languages. Takeaway: semantics is the meaning behind the code that makes the computer do something you can rely on."}
{"Major": "Computer Science", "Term": "floating-point arithmetic", "Explanation": "- Basic idea: Floating-point arithmetic is the way computers store and calculate numbers with a wide range of sizes using a fixed amount of precision and a scaling factor.\n- Real-world example: Think of a ruler with only a few marks—0.1 and 0.2 each get rounded to the nearest mark, so adding them might not give a perfect 0.3.\n- Takeaway: It lets computers handle huge ranges, but tiny rounding errors can creep in, especially in big calculations."}
{"Major": "Computer Science", "Term": "quicksort", "Explanation": "- Basic idea: Quicksort sorts a list by picking a pivot item, moving smaller items to one side and larger items to the other, and then sorting those sides recursively.\n\n- Real-world example: Imagine sorting a pile of basketballs by size. You pick one ball as the pivot, slide smaller balls to the left and bigger balls to the right, then repeat on each side until everything is in order.\n\n- Why it matters: Quicksort is fast and practical for large lists, and it demonstrates the key idea of divide and conquer—break the problem into smaller, similar problems and solve them step by step."}
{"Major": "Computer Science", "Term": "agent-based model (ABM)", "Explanation": "- Basic idea in one sentence: ABM is a way to study complex systems by simulating many small “agents”—like people or cars—that follow simple rules and interact with each other. \n- Real-world example (1–2 sentences): Imagine modeling how a crowd evacuates a building; each person moves toward an exit based on what nearby people and obstacles are doing. From those simple rules, you can see patterns like bottlenecks and slow zones emerge.\n- Why it matters (quick takeaway): It helps researchers and designers test ideas and explore outcomes before real-world trials, so you can improve safety, traffic flow, or policies by watching emergent, system-wide effects. Takeaway: small, local decisions can lead to big, sometimes surprising, overall behavior."}
{"Major": "Computer Science", "Term": "big data", "Explanation": "- Basic idea: Big data is like completing a very large puzzle—the more pieces you have, the clearer the overall picture (patterns and insights) becomes.\n\n- Real-world example: An online retailer tracks millions of customer interactions—views, searches, and purchases—to personalize recommendations and optimize pricing. This helps them predict what you might want next and adjust offers in real time.\n\n- Why it matters (quick takeaway): Big data helps people and organizations make smarter, faster decisions at scale, but you need the right tools and practices to manage a huge amount of data coming in quickly and in many different forms."}
{"Major": "Computer Science", "Term": "class", "Explanation": "- Basic idea in one sentence: A class is a blueprint for making objects in code, describing what data they hold and what they can do.\n\n- Real-world example in 1–2 sentences: Think of a class called Car. It defines data like color and model, and actions like start or honk. You can create many car objects—from a red Tesla to a blue Civic—from that same blueprint, each with its own color and model.\n\n- Why it matters with takeaway: Classes keep code organized and reusable, making it easier to build big programs by reusing the same blueprint to create many similar objects. Takeaway: classes turn ideas into reusable building blocks that help manage complexity."}
{"Major": "Computer Science", "Term": "coding theory", "Explanation": "- 1) Basic idea: Coding theory studies how to encode messages with extra information so noise can be detected and corrected.\n\n- 2) Real-world example: When data is sent over a noisy line or wireless signal, extra bits let the receiver detect and fix some mistakes. CDs, DVDs, and internet packets use these codes to recover content even if part of the data is corrupted.\n\n- 3) Why it matters: Takeaway: coding theory makes digital communication and storage reliable by adding just the right amount of redundancy."}
{"Major": "Computer Science", "Term": "computability theory", "Explanation": "- Basic idea (one sentence): Computability theory asks which problems can be solved by a computer in principle and which cannot, no matter how much time or clever methods you use.\n\n- Real-world example (1–2 sentences): It’s easy to write a program to check if a list has duplicates, but there are questions with no general step-by-step method that always works for every possible input—whether a program will ever finish running, for example. That kind of problem is fundamentally unsolvable by a single algorithm.\n\n- Why it matters (quick takeaway): It helps us see the limits of what computers can do and when we should settle for practical, approximate, or restricted solutions rather than perfect ones. In short: some problems can’t be solved by any algorithm, so we design workarounds instead."}
