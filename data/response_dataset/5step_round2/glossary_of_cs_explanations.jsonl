{"Major": "Computer Science", "Term": "quantum computing", "Explanation": "1. One-sentence definition\nQuantum computing uses qubits that can be 0, 1, or both at once, leveraging quantum rules to solve some problems faster than classical computers.\n\n2. Simple intuition with everyday example\nIntuition: a qubit behaves like a spinning coin that is heads and tails until you measure it; many qubits together amplify the correct answer through interference.\n\n3. Key components and related concepts\n- Qubits\n- Superposition\n- Entanglement\n- Quantum gates\n- Interference\n- Measurement and decoherence\n\n4. Clear real-world analogy with mapping\nAnalogy: a choir and a conductor. Qubits are the singers; superposition is singing multiple notes at once; gates are the conductor’s cues; entanglement is linked singers; interference shapes the right harmony; measurement is listening to the final chord.\nMapping:\n- Singers → qubits\n- Multiple notes at once → superposition\n- Conductor’s cues → gates\n- Linked singers → entanglement\n- Harmony shaping → interference\n- Final chord → measurement\n- Background hiss → decoherence\n\n5. Common misconceptions and clarifications\n- Misconception: they replace classical computers for all tasks. Reality: best for specific problems; many tasks stay classical.\n- Misconception: qubits are just tiny 0/1 bits. Reality: they store quantum states and reveal outcomes only upon measurement.\n- Misconception: more qubits mean automatic speedups. Reality: depends on algorithms and low error rates; current devices are noisy."}
{"Major": "Computer Science", "Term": "big O notation", "Explanation": "1) One-sentence definition:\nBig O notation describes how an algorithm’s resource use (time or memory) grows as the input size increases.\n\n2) Simple intuition with everyday example:\nIntuition: imagine sorting a deck of cards. With 10 cards it takes some time; with 100 cards you’ll spend roughly ten times as much effort—the total work scales with the deck size.\n\n3) Key components and related concepts:\n- n = input size\n- Growth rates: O(1), O(log n), O(n), O(n log n), O(n^2), etc.\n- Upper bound (worst-case)\n- Tight bound (Big Theta) and lower bound (Big Omega)\n- Time vs. space (memory) complexity\n- Constants and lower-order terms are ignored in Big O\n\n4) Clear real-world analogy with mapping:\nAnalogy: sorting a deck of cards by hand.\n- n cards ↔ input size\n- Insertion work per card ↔ per-item work\n- Total time ↔ overall Big O\n- If you scan for position (linear search) for each card → about 1+2+...+n comparisons → O(n^2)\n- If you used a faster search then insert (conceptually) → demonstrates how different methods affect the growth rate (e.g., n log n)\n\n5) Common misconceptions and clarifications:\n- Misconception: O(n) is the exact time. Correction: it is a growth bound, ignoring constants.\n- Misconception: O(n^2) is always slower than O(n log n). Correction: asymptotically yes, but constants matter for small n.\n- Misconception: Big O only measures time. Correction: it can describe space (memory) too."}
{"Major": "Computer Science", "Term": "semantics", "Explanation": "1) One-sentence definition\nSemantics in computer science is the meaning or effect of a program when it runs—the results it produces and how it changes the computer’s state.\n\n2) Simple intuition with everyday example\nThink of a recipe: the words are syntax, but semantics is what happens in the kitchen—how the ingredients become a dish and how the pantry changes as you cook.\n\n3) Key components and related concepts\n- Data values and types (what the code talks about)\n- Statements and expressions (how code computes and changes state)\n- Control flow and side effects (what runs when, and what the world around changes)\n- Input/output and interaction\n- Related ideas: syntax, compilers/interpreters, and formal semantics (operational/denotational)\n\n4) Clear real-world analogy with mapping\nAnalogy: a cookbook recipe.\n- Code/recipe steps -> program statements\n- Ingredients -> data/values\n- Kitchen state/memory -> computer memory and registers\n- Oven/stove -> CPU/runtime environment\n- Finished dish/output -> program result or final state\nMapping: steps cause state changes; ingredients determine possible outcomes; the kitchen state tracks progress; the CPU executes steps to produce the dish.\n\n5) Common misconceptions and clarifications\n- Misconception: semantics = syntax. Correct: semantics is about meaning and effects, not formatting.\n- Misconception: same words mean same thing in all contexts. Correct: meaning can differ with evaluation order and environment.\n- Misconception: semantics only matters for language design. Correct: it governs how any program behaves on real hardware."}
{"Major": "Computer Science", "Term": "floating-point arithmetic", "Explanation": "1) One-sentence definition:\nFloating-point arithmetic is the computer method to represent and calculate real numbers by storing a sign, a significand, and an exponent so the decimal point can move.\n\n2) Simple intuition with everyday example:\nThink of scientific notation on a calculator: you can write numbers as 3.14 × 10^5 or 2.7 × 10^-3 to cover very large or very small values by shifting the decimal point.\n\n3) Key components and related concepts:\n- Sign: positive or negative\n- Significand (mantissa): the stored digits of the number\n- Exponent: how far the decimal point is moved\n- Normalization: keeping numbers in a standard form (about 1.x × 10^n)\n- Precision and rounding: finite digits cause small errors\n- Range and limits: possible overflow/underflow\n- Representation standard: common hardware use IEEE 754\n\n4) Clear real-world analogy with mapping:\nAnalogy: using a scientific notation mode on a calculator.\n- Sign -> the number’s positive/negative sign\n- Significand -> the digits you store (mantissa)\n- Exponent -> the power of ten (scale)\n- Normalization -> the standard form kept by the system\n- Limited precision -> rounding errors and possible overflow/underflow\n\n5) Common misconceptions and clarifications:\nMisconception: floating-point numbers are exact representations of all real numbers.\nWhy wrong: finite digits and binary representation make many decimals approximate (e.g., 0.1).\nCorrect perspective: be mindful of rounding, use tolerance when comparing, and expect tiny errors in results."}
{"Major": "Computer Science", "Term": "quicksort", "Explanation": "1. One-sentence definition\nQuicksort is a sorting method that picks a pivot, partitions the array so items less than the pivot go left and items greater go right, and then recursively sorts the two sides.\n\n2. Simple intuition with everyday example\nImagine sorting a pile of books by weight: choose a reference weight (pivot), move lighter books to one side and heavier ones to the other, then sort each side again.\n\n3. Key components and related concepts\n- Pivot: the chosen reference element\n- Partition: rearrange so left side < pivot, right side > pivot\n- Recursion: sort subarrays\n- Base case: size 0 or 1\n- In-place; time: average O(n log n), worst O(n^2); not stable by default\n\n4. Real-world analogy with mapping\nAnalogy: sorting a deck of cards around a pivot card.\nMapping: pivot card = pivot; left pile = cards < pivot; right pile = cards > pivot; sort each pile recursively; piles of 0–1 cards are done; all rearranges happen in one deck (in place).\n\n5. Common misconceptions and clarifications\n- Misconception: Quicksort is always the fastest. Wrong because performance depends on pivot and data; average is good, but worst-case can be slow.\n- Clarification: It is typically in-place (uses little extra memory) and not stable by default; stability requires extra work."}
{"Major": "Computer Science", "Term": "agent-based model (ABM)", "Explanation": "1) One-sentence definition\nAn agent-based model (ABM) is a computer simulation that uses many independent agents, each following simple rules, interacting in a shared environment to produce complex system behavior.\n\n2) Simple intuition with everyday example\nThink of many people driving in a city: each driver acts on simple habits (stay in lane, stop at red), and together they create the traffic patterns you experience.\n\n3) Key components and related concepts\n- Agents (individual actors with goals)\n- Rules (simple decision rules)\n- Environment (road network, space, or context)\n- Interactions (how agents affect one another)\n- Emergence (patterns or behaviors at the system level)\n- Simulation (time-stepped updates)\n- Data/outputs (measured results)\nRelated ideas: heterogeneity (differences among agents), randomness, networks, calibration.\n\n4) Clear real-world analogy with mapping\nAnalogy: city traffic simulation.\n- Agents → drivers/cars\n- Rules → driving habits and destination goals\n- Environment → road network and signals\n- Interactions → following distance, lane changes, yielding\n- Emergence → congestion patterns, travel times\n- Simulation steps → time ticks\n- Data → travel times, wait times, throughput\n\n5) Common misconceptions and clarifications\n- Misconception: ABMs predict exact futures. Why wrong: they show possible patterns under assumptions, not a precise forecast; outcomes depend on rules and parameters.\n- Misconception: ABMs need lots of data. Why wrong: simple rules can reveal mechanisms; data helps check plausibility but isn’t mandatory."}
{"Major": "Computer Science", "Term": "big data", "Explanation": "1. One-sentence definition\nBig data are extremely large and fast-moving datasets that overwhelm traditional storage and analysis methods.\n\n2. Simple intuition with everyday example\nIt’s like a city’s traffic system getting streams of data from countless sensors and apps in real time—so much information that old tools can’t keep up.\n\n3. Key components and related concepts\n- Volume, Velocity, Variety (the 3Vs)\n- Veracity (data quality) and Value (useful insights)\n- Tools and concepts: Hadoop, Spark; data storage (data lake); analytics and data science\n\n4. Clear real-world analogy with mapping\nAnalogy: a city traffic control center.\n- Data sources (cameras, road sensors, apps) → incoming traffic reports\n- Storage/warehouse → central database or data lake\n- Processing/analysis → real-time signal adjustments and dashboards\n- Insights/decisions → optimized lights, detours, public dashboards\n\n5. Common misconceptions and clarifications\n- Misconception: More data automatically yields better insights. Truth: quality, relevance, and proper models matter.\n- Misconception: Only tech giants use big data. Truth: used across healthcare, finance, education, government, etc.\n- Misconception: Big data alone provides answers. Truth: it requires cleaning, modeling, and interpretation to derive value."}
{"Major": "Computer Science", "Term": "class", "Explanation": "1) One-sentence definition\nA class is a blueprint that defines a type of object by listing its data and the actions it can perform.\n\n2) Simple intuition with everyday example\nThink of a class like a recipe or blueprint you use to make actual items; it specifies features and abilities, and you can bake many copies from it.\n\n3) Key components and related concepts\n- Data/attributes (color, size, name)\n- Actions/methods (what it can do)\n- Constructor (how a new object is created)\n- Instance (an actual object)\n- Related ideas: inheritance, encapsulation, polymorphism\n\n4) Clear real-world analogy with mapping\nAnalogy: blueprint for a house\n- Class = blueprint\n- Instance = actual house built from the blueprint\n- Attributes = number of rooms, color, size\n- Methods = open door, turn on lights\n- Constructor = the building process that yields a house\n- Inheritance = a variation of the blueprint (e.g., deluxe model) reusing and extending features\n\n5) Common misconceptions and clarifications\n- Misconception: Class = object. Clarification: class is the plan; object is a built example.\n- Misconception: One class creates only one object. Clarification: many objects can be created from the same class.\n- Misconception: Inheritance copies fields. Clarification: it defines a relationship to reuse/extend features; specifics can be overridden."}
{"Major": "Computer Science", "Term": "coding theory", "Explanation": "1. One-sentence definition:\nCoding theory studies how to detect and correct errors in information that is transmitted or stored.\n\n2. Simple intuition with everyday example:\nIt’s like packing a fragile item with padding and a packing slip so you can still read or reconstruct it if some contents are damaged in transit.\n\n3. Key components and related concepts:\n- Code and codeword: original data vs encoded data with extra bits\n- Redundancy: extra information added\n- Error detection vs error correction: discovering problems vs fixing them\n- Encoding/decoding algorithms: how to create and recover codewords\n- Channel and noise models: what can go wrong in transmission or storage\n\n4. Clear real-world analogy with mapping:\nAnalogy: sending a fragile item in a padded box with a packing slip.\n- Item in box = the original message\n- Padding and packing slip = redundancy and checks\n- Shipping process with rough handling = the noisy channel\n- Recipient using the packing slip and rules = the decoder\n- How much misplacement you can recover from = the code’s error-tolerance (distance)\n\n5. Common misconceptions and clarifications:\nMisconception: More redundancy always makes things better.\nWhy it’s wrong: it reduces efficiency; there is a trade-off.\nCorrect view: codes balance reliability and efficiency; choose redundancy to fit the need."}
{"Major": "Computer Science", "Term": "computability theory", "Explanation": "1) One-sentence definition: Computability theory asks which problems can be solved by a step-by-step procedure (algorithm) and how the required effort grows.\n\n2) Simple intuition with everyday example: If you can write a finite recipe that always produces an answer, a computer can follow it. If no such recipe exists for all cases, the problem may be unsolvable by machines.\n\n3) Key components and related concepts:\n- Algorithms and models of computation (e.g., Turing machines)\n- Decidable vs. undecidable problems\n- Computable functions and time/space complexity\n- Church-Turing thesis and reducibility\n\n4) Clear real-world analogy with mapping:\nAnalogy: a factory that runs blueprints on a machine.\n- Problem to task: the question you want answered\n- Blueprint/algorithm: the step-by-step method\n- Machine/computer: the device that executes steps\n- Time/space: how long and how much memory you need\n- Undecidable task: no blueprint exists\n- Reducing problems: recasting a hard task as easier, solvable steps\nMapping: each part of the analogy corresponds to the technical idea above.\n\n5) Common misconceptions and clarifications:\n- Misconception: if a human can solve it, a computer can too. Correction: only if there is a finite, mechanical procedure.\n- Misconception: all hard problems are impossible. Correction: many are solvable but may be impractical; some are provably unsolvable."}
