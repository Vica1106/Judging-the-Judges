{"Major": "Computer Science", "Term": "quantum computing", "Explanation": "Quantum computing is the computational paradigm that encodes information in quantum states and processes it by unitary dynamics, followed by measurement. A qubit is a two-dimensional Hilbert space spanned by {|0>, |1>}; an n-qubit system resides in H = (C^2)^{⊗n}. Pure states are unit vectors |ψ> ∈ H; mixed states are density operators ρ on H. Computation is modeled by a quantum circuit: a finite sequence of quantum gates, each a unitary operator U_j acting on a subset of qubits, drawn from a universal gate set (e.g., single-qubit rotations and entangling gates such as CNOT). The global evolution is U = U_m ... U_1 with |ψ_f> = U|ψ_i>. Measurement in a chosen basis yields classical outcomes with probabilities p_b = ⟨ψ_f|Π_b|ψ_f⟩ or p_b = Tr(Π_b ρ_f) per Born rule; post-measurement state collapses accordingly. A central feature is superposition and entanglement; amplitudes interfere, enabling computational speedups. Complexity: BQP is the class of problems solvable in polynomial time with bounded error on a quantum computer; BPP ⊆ BQP ⊆ EXP; notable algorithms include Shor’s factoring and Grover’s search. Practical realization requires quantum error correction and fault-tolerance due to decoherence and errors; no-cloning theorem restricts state replication."}
{"Major": "Computer Science", "Term": "big O notation", "Explanation": "Big O notation characterizes the asymptotic growth of a function up to constant factors, yielding a coarse upper bound on its magnitude.\n\nFormal definitions:\n- For functions f, g: N → R with g(n) > 0 for sufficiently large n, f ∈ O(g) iff ∃ c > 0 and n0 ∈ N such that ∀ n ≥ n0, |f(n)| ≤ c|g(n)|.\n- f ∈ Ω(g) iff ∃ c > 0 and n0 ∈ N with ∀ n ≥ n0, |f(n)| ≥ c|g(n)|.\n- f ∈ Θ(g) iff ∃ c1, c2 > 0 and n0 ∈ N with ∀ n ≥ n0, c1|g(n)| ≤ |f(n)| ≤ c2|g(n)|.\n\nKey properties:\n- O-sets are closed under multiplication by positive constants: O(cg) = O(g).\n- If f ∈ O(g) and h ∈ O(g), then f + h ∈ O(g).\n- Transitivity: if f ∈ O(g) and g ∈ O(h), then f ∈ O(h).\n\nRemarks:\n- O-notation ignores constant factors and lower-order terms; it preserves the dominant growth rate.\n- Little-o: f ∈ o(g) iff lim_{n→∞} f(n)/g(n) = 0.\n\nExample: 3n^2 + 2n + 1 ∈ O(n^2)."}
{"Major": "Computer Science", "Term": "semantics", "Explanation": "Semantics (in Computer Science) is the rigorous assignment of mathematical meaning to the syntactic objects of a programming language, in a way that supports prediction, reasoning, and verification.\n\nFormal definitions\n- Given a language L with syntax S and semantic domain D, a semantic valuation ⟦·⟧ assigns to each syntactic object α ∈ S a meaning ⟦α⟧ ∈ D, typically required to be compositional: the meaning of a constructed form is determined by the meanings of its constituents.\n- Semantic frameworks:\n  - Operational semantics: meaning expressed by evaluation of configurations ⟨code, state⟩ via relations or transition systems (small-step or big-step).\n  - Denotational semantics: ⟦·⟧ maps programs/expressions to mathematical objects in D, ensuring ⟦C⟧ = F(⟦α1⟧,…, ⟦αk⟧) for constructors C built from subparts αi (compositionality).\n  - Axiomatic semantics: meaning given by logical judgments, e.g., Hoare triples {P} C {Q}.\n\nIllustrative denotational definitions (imperative language with integers)\n- Domains: V = Z, Store Σ = Var → Z.\n- ⟦n⟧σ = n; ⟦x⟧σ = σ(x); ⟦e1+e2⟧σ = ⟦e1⟧σ + ⟦e2⟧σ.\n- ⟦x := e⟧σ = σ[x ↦ ⟦e⟧σ]; ⟦skip⟧σ = σ; ⟦s1; s2⟧σ = ⟦s2⟧(⟦s1⟧σ).\n\nCorrectness concepts: soundness (semantic judgments hold in all models) and adequacy (alignment between operational and denotational interpretations)."}
{"Major": "Computer Science", "Term": "floating-point arithmetic", "Explanation": "Floating-point arithmetic is the representation and manipulation of real numbers in finite precision using a fixed base β, a precision p, and an exponent range [e_min, e_max]. A nonzero representable number has the form x = (-1)^s × m × β^e with s ∈ {0,1}, m ∈ [1,β) normalized as m = ∑_{k=0}^{p-1} d_k β^{-k}, with d_0 ∈ {1,...,β−1} and d_k ∈ {0,...,β−1}. Zero is represented separately. Denormalized numbers allow m ∈ (0,1) with e = e_min. The machine rounds to the nearest representable value (ties to even) under a chosen rounding mode; operations are denoted fl(x ⊙ y) for the rounded result of the exact operation x ⊙ y.\n\nA unit roundoff u = 1/2 β^{1−p} bounds typical relative rounding error: fl(x ⊙ y) = (x ⊙ y)(1+δ), |δ| ≤ u, subject to overflow/underflow and exceptional cases. Floating-point arithmetic thus exhibits finite precision, rounding error, potential loss of associativity, and phenomena such as cancellation and underflow. The set of representable numbers is finite and nonuniformly spaced, especially near zero."}
{"Major": "Computer Science", "Term": "quicksort", "Explanation": "Quicksort is a comparison-based, in-place, divide-and-conquer sorting algorithm for finite sequences over a totally ordered domain. Given a sequence A[1..n], if n ≤ 1, stop; otherwise select a pivot x ∈ A and apply a partitioning procedure P that reorganizes A into A[1..q−1] consisting of elements < x, A[q] = x (the pivot), and A[q+1..n] consisting of elements > x (or ≥ x with duplicates handled by the same partition invariant). The index q is the final position of the pivot. Recursively sort A[1..q−1] and A[q+1..n]. The algorithm is correct by induction on n: after partition, left elements precede the pivot and right elements succeed it; recursive sorts place them in order, and concatenation yields a sorted sequence.\n\nLet T(n) denote time; with k elements less than the pivot, T(n) = T(k) + T(n − k − 1) + Θ(n). The average-case complexity is Θ(n log n); worst-case is Θ(n^2) when partitions are highly unbalanced. Auxiliary space is O(log n) on average (due to recursion depth), O(n) worst-case. Quicksort is not stable in general; stable variants exist with extra storage. Common partition schemes include Lomuto and Hoare, and random pivot selection improves expected performance."}
{"Major": "Computer Science", "Term": "agent-based model (ABM)", "Explanation": "An agent-based model (ABM) is a computational framework for simulating heterogeneous, autonomous agents embedded in an environment, whose local interactions generate emergent macro-scale phenomena.\n\nFormal components\n- Agents: A = {a_i} with internal state s_i(t) ∈ S_i, attributes θ_i, and a decision policy π_i: P_i × E_i → Actions. \n- Environment: E with state e(t) ∈ E and mechanisms for perception and influence on agents.\n- Interaction topology: G, defining neighborhoods N_i over which agents observe or affect others.\n- Dynamics: time is discrete; agent updates: s_i(t+1) = F_i(s_i(t), α_i(t), e_i(t), {s_j(t) | j ∈ N_i}, ξ_i), where α_i(t) is the chosen action and ξ_i represents stochasticity; environment update: e(t+1) = H(e(t), {α_i(t)}, η(t)).\n- Global state and emergence: S(t) = ({s_i(t)}, e(t)); emergent properties M(t) = Φ(S(t))—macroscopic regularities not specified by micro-rules.\n\nKey characteristics\n- Heterogeneity, bounded rationality/adaptation, local interactions, potential stochasticity.\n- Bottom-up modeling; macro phenomena arise from micro rules rather than being imposed.\n- Validation considerations: verification, calibration, sensitivity analysis, empirical comparison."}
{"Major": "Computer Science", "Term": "big data", "Explanation": "Big data refers to data collections whose size, generation rate, and structural heterogeneity exceed the capabilities of traditional data management and processing technologies. Formally, a dataset D is big data with respect to a computational environment E if conventional systems (e.g., single-node relational databases) cannot store, index, or analyze D within acceptable latency and resource constraints, thereby requiring distributed storage, parallel computation, and specialized algorithms.\n\nFive characteristic dimensions (the 5 Vs) are commonly formalized:\n- Volume: substantial data magnitude beyond single-machine capacity.\n- Velocity: rapid data inflow and real-time or near-real-time processing requirements.\n- Variety: heterogeneity of data formats, structures, and schemas.\n- Veracity: concerns about data quality, provenance, and reliability.\n- Value: potential for deriving meaningful, decision-relevant insights.\nSome frameworks also include variability (non-stationary data flows) and scalability constraints as ancillary considerations.\n\nThus, big data encompasses the data lifecycle—capture, curation, storage, integration, search, sharing, transfer, analysis, and visualization—implemented via scalable distributed architectures and governance practices."}
{"Major": "Computer Science", "Term": "class", "Explanation": "In object-oriented programming, a class is a syntactic construct that defines a user-defined type T_C. A class C comprises:\n\n- a finite set F_C of data members (fields) each with an associated type;\n- a finite set M_C of operations (methods) each with a signature specifying parameter types and a return type;\n- an optional set I_C of invariants—logical predicates over the fields that must hold in every reachable state;\n- constructors for initializing instances;\n- an access-control specification governing visibility of members (e.g., public, protected, private).\n\nSemantics: A class defines the carrier type T_C. An object o of type T_C possesses a state assignment to F_C that satisfies I_C; operations in M_C act as stateful procedures on such objects, subject to invariants. Static members (if supported) are associated with the class itself, not with any instance.\n\nInheritance: A class D may extend a superclass C, thereby inheriting F_C and M_C, potentially overriding methods. Subtyping ensures that an object of type D can be used wherever a value of type C is expected (polymorphism).\n\nGenerics: A parameterized class uses type arguments to form a family of related types."}
{"Major": "Computer Science", "Term": "coding theory", "Explanation": "Coding theory is the mathematical study of the design, analysis, and implementation of codes that enable reliable communication and data storage over noisy channels.\n\nLet F_q denote a finite field. A q-ary code C of length n is a subset C ⊆ F_q^n with M = |C| codewords. The rate is R = (log_q M)/n; if C is linear of dimension k (an [n,k] code), then M = q^k and C = {uG : u ∈ F_q^k} for a generator matrix G ∈ F_q^{k×n}, with a parity-check matrix H ∈ F_q^{(n−k)×n} satisfying CH^T = 0 and C = {y ∈ F_q^n : yH^T = 0}.\n\nThe Hamming distance d_H(x,y) induces the minimum distance d = min_{x≠y∈C} d_H(x,y). Thus C can detect up to d−1 errors and correct up to t = ⌊(d−1)/2⌋ errors. Encoding is E(u) = uG; decoding maps y ∈ F_q^n to an estimate x̂ ∈ C, via ML decoding or syndrome decoding with s = yH^T.\n\nChannels and bounds: for a discrete memoryless channel, coding reduces the error probability as block length grows; capacity C bounds achievable rates. Bounds include Singleton d ≤ n−k+1 and the Hamming bound. Code families include Reed–Solomon, BCH, LDPC, turbo, polar, and convolutional codes."}
{"Major": "Computer Science", "Term": "computability theory", "Explanation": "Computability theory investigates the limits of algorithmic solvability. It formalizes the notion of an effective procedure using canonical models of computation, notably Turing machines, the lambda calculus, and μ-recursive functions; these models are equivalent in expressive power (Church–Turing thesis). A decision problem is represented as a language L ⊆ Σ*, and L is decidable (recursive) iff there exists a total Turing machine that, on input x, halts with acceptance precisely when x ∈ L. A language is recognizable (recursively enumerable) iff there exists a (potentially partial) machine that halts and accepts exactly the strings in L (non-members may loop). A function f: Σ* → Γ* is computable if a Turing machine computes f and halts on all inputs (total); partial computable otherwise.\n\nKey results: Halting problem H = {⟨M,w⟩ | M halts on w} is r.e.-complete and undecidable. Reductions: A ≤_m B. Rice's theorem: every nontrivial semantic property of partial computable functions is undecidable. Computability theory contrasts decidability with resource-bounded complexity and underpins the thesis that effective computation is captured by the Church–Turing framework."}