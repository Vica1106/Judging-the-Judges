{"Major": "Artificial Intelligence", "Term": "Selective Linear Definite Clause Resolution", "Explanation": "Sections: Selective Linear Definite Clause Resolution (SLD)\n\n1) High-level idea\n- A goal-driven way to prove queries from a set of definite clauses by repeatedly picking a single subgoal and resolving it with a clause that matches its head.\n\n2) Precise definition\n- Program: a set of definite (Horn) clauses of the form H :- B1, ..., Bn.\n- Goal: a finite conjunction of atoms.\n- SLD step: pick a selected atom A in the current goal; find a clause H :- B1,...,Bn with A unifiable with H; let θ be the most general unifier (MGU); replace A by B1,...,Bn and apply θ to the rest of the goal.\n- Derivation: a sequence of such steps; success if the goal becomes empty; failure if no step is possible.\n\n3) Intuition and a simple example\n- Idea: “simulate” forward reasoning only on one subgoal at a time.\n- Example: Program: grandparent(X,Z) :- parent(X,Y), parent(Y,Z). Facts: parent(alice,bob).parent(bob,carl).\n  Query: grandparent(alice,carl).\n  1) Resolve with head grandparent(X,Z) → θ1: X=alice, Z=carl; new goal: parent(alice,Y), parent(Y,carl).\n  2) Resolve first subgoal with parent(alice,bob) → Y=bob; new goal: parent(bob,carl).\n  3) Resolve with parent(bob,carl) → success.\n\n4) Formal rules (core steps)\n- Step: G := G \\ {A} ∪ {B1,...,Bn} θ, where A unifies with H of some clause H :- B1,...,Bn, and θ is the MGU.\n- Repeat until G is empty (success) or no clause matches (failure). Selection rule determines which A to pick.\n\n5) Mechanism (brief)\n- Pick a subgoal, unify, substitute, replace, repeat; backtracking may explore alternatives.\n\n6) Common misconceptions and clarifications\n- Not every proof search terminates; completeness depends on search strategy and backtracking.\n- It is goal-directed, not a blind, forward-chaining prove-all.\n\n7) Takeaway (one sentence)\n- SLD resolution is Prolog’s standard, goal-directed method for proving questions from definite clauses by solving one subgoal at a time through unification.\n\nKey terms\n- SLD resolution: goal-driven proof method for definite clauses.\n- Definite clause: a Horn clause with exactly one positive literal.\n- Unification: finding a substitution making two atoms identical.\n- Most General Unifier (MGU): the least restrictive unifier that makes terms equal.\n- Selection rule: rule that chooses which subgoal to resolve next."}
{"Major": "Artificial Intelligence", "Term": "Big O notation", "Explanation": "1) High-level idea\n- Big O describes how runtime or memory grows as input size n increases. It focuses on growth rate, not exact numbers.\n\n2) Precise definition\n- T(n) = O(f(n)) if ∃ c > 0 and n0 such that for all n ≥ n0, T(n) ≤ c·f(n). f(n) is a simple growth function (e.g., n, n^2, log n).\n\n3) Intuition and simple example\n- If a loop runs n times, time ≈ n → O(n). Binary search on sorted data runs ≈ log2 n steps → O(log n). Doubling n roughly doubles time; log n grows slowly.\n\n4) Formal rules and common classes\n- Drop constants and lower-order terms when comparing growth.\n- Common classes: O(1), O(n), O(n log n), O(n^2), O(2^n).\n- O is an upper bound; Theta denotes a tight bound (both upper and lower).\n\n5) Step-by-step mechanism\n- Identify the dominant factor in T(n), express it as a function of n, compare to f(n), and pick constants c and n0 to satisfy the definition.\n\n6) Misconceptions and clarifications\n- Not exact timing; it’s about growth rate. O(n) does not guarantee a fixed linear time in every scenario.\n\n7) Takeaway\n- Big O tells you how the resource use grows with input size.\n\nKey terms\n- n: input size\n- Time complexity: growth of runtime with n\n- Big O notation: an upper bound on growth rate (up to constants)"}
{"Major": "Artificial Intelligence", "Term": "neural machine translation (NMT)", "Explanation": "High-level idea\n- Neural networks learn to translate text by reading a source sentence and producing a fluent target sentence, trained on lots of bilingual data.\n\nPrecise definition\n- Neural Machine Translation (NMT) uses neural models to map x (source) to y (target) by modeling p(y|x) with an encoder–decoder architecture, often with attention, trained end-to-end.\n\nIntuitive explanation and simple example\n- The encoder summarizes x into a context, the decoder generates y one word at a time, choosing each word to fit both the source context and previously generated words. Example: x = \"Hello\" → y = \"Hola\" in Spanish, guided by surrounding words and learned patterns.\n\nFormal definitions\n- p(y|x) = ∏_t p(y_t | y_{<t}, x; θ)\n- Training objective: maximize ∑ log p(y|x) over data; inference uses greedy decoding or beam search.\n\nStep-by-step mechanism\n- Encode x into context vectors.\n- Decode y with attention that focuses on relevant source positions.\n- Compute cross-entropy loss; update parameters θ.\n- Inference: generate y by selecting likely next words (beam search enhances quality).\n\nCommon misconceptions\n- Not word-for-word; uses context and subword units to handle rare words; requires large data and compute; may be fluent but wrong.\n\nOne-sentence takeaway\n- NMT learns to predict the best target sentence given the source, using neural nets and learned word-by-word dependencies.\n\nKey terms\n- NMT: Neural Machine Translation; \n- Encoder–Decoder: architecture that converts source to target representations and then to text; \n- Attention: mechanism linking source positions to target generation; \n- p(y|x): probability of a target given a source; \n- Beam search: decoding method exploring multiple candidate translations."}
{"Major": "Artificial Intelligence", "Term": "NP-hardness", "Explanation": "High-level idea\n- NP-hard problems are among the hardest in the class NP; solving one quickly would let us solve every NP problem quickly.\n\nPrecise definition\n- Q is NP-hard if, for every problem L in NP, there is a polynomial-time computable function f that maps instances x of L to instances f(x) of Q such that x is a yes-instance for L iff f(x) is a yes-instance for Q.\n\nIntuition and simple example\n- Imagine turning any NP puzzle into one big instance of Q. If you can solve Q fast, you can solve all NP puzzles fast.\n- Example: Subset Sum (decision) is NP-complete, so it is NP-hard; many other problems reduce to it, showing their difficulty.\n\nFormal definitions/rules\n- Reduction: a polynomial-time mapping that preserves yes/no answers.\n- Polynomial time: algorithm runs in time bounded by a polynomial in input size.\n\nStep-by-step mechanism (no chain-of-thought)\n- To prove Q is NP-hard, pick a known NP-hard problem P.\n- Construct a polynomial-time reduction from P to Q.\n- Show that yes-instances correspond under the reduction.\n\nCommon misconceptions\n- NP-hard does not mean “unsolvable in general”; many NP-hard problems have efficient practical algorithms for special cases.\n- NP-hard vs NP-complete: NP-complete problems are both NP-hard and in NP.\n\nTakeaway\n- NP-hardness formalizes when a problem is at least as hard as the hardest NP problems.\n\nKey terms\n- NP: class of problems verifiable in polynomial time\n- NP-hard: as hard as any problem in NP\n- NP-complete: in NP and NP-hard\n- reduction: polynomial-time mapping preserving yes/no\n- polynomial time: time bounded by a polynomial in input size"}
{"Major": "Artificial Intelligence", "Term": "true quantified Boolean formula", "Explanation": "Sections: True Quantified Boolean Formula (TQBF)\n\n1) High-level idea\n- A TQBF is a fully quantified Boolean formula that evaluates to true. It tests how quantifiers like “for all” and “there exists” interact in logical statements.\n\n2) Precise definition\n- A QBF has the form Q1 x1 Q2 x2 ... Qn xn φ, where each Qi is ∀ or ∃ and φ is a propositional formula over x1,...,xn. The formula is true (a true quantified Boolean formula) if, under standard semantics, the quantified statement holds. A closed QBF has no free variables.\n\n3) Intuition and simple example\n- Intuition: Can we pick variable values to satisfy φ, no matter how the universal variables are chosen?\n- Example: ∀x ∃y (x ∨ y). If x=0, pick y=1; if x=1, the inside is true regardless of y. Hence the formula is true.\n\n4) Formal definitions/rules\n- Semantics: ∃y ψ is true iff ψ is true for some y; ∀y ψ is true iff ψ is true for all y. Apply this step by step from the inside out.\n\n5) Step-by-step mechanism\n- Identify the prefix, evaluate φ over assignments for bound variables, combine results with AND (∀) or OR (∃) across assignments.\n\n6) Common misconceptions\n- Not every QBF is true; “true” means true under the quantifier order. TQBF is distinct from propositional SAT and is PSPACE-complete.\n\n7) Takeaway\n- TQBF asks whether a fully quantified Boolean statement can be guaranteed true under the given order of quantifiers.\n\nKey terms\n- QBF: Quantified Boolean Formula; a Boolean formula with quantifiers.\n- TQBF: True quantified Boolean formula; a closed QBF that evaluates to true.\n- Propositional formula: A Boolean formula without quantifiers.\n- Quantifier prefix: The sequence of ∀/∃ before the body φ.\n- Semantics: Rules for evaluating ∃ (exists) and ∀ (for all)."}
{"Major": "Artificial Intelligence", "Term": "algorithmic probability", "Explanation": "1) High-level idea\n- Algorithmic probability asks: if we generate a random program for a universal computer, what is the chance its output is a given string x?\n\n2) Precise definition\n- For a fixed universal prefix-free machine U, m(x) = sum over all programs p with U(p) = x of 2^{-|p|} (|p| is the length of p in bits). The prefix-free condition makes the total sum over all x at most 1. This distribution is not computable in general and can depend on the chosen machine, up to a constant factor.\n\n3) Intuition and simple example\n- Shorter programs are weighted more heavily, so simpler outputs tend to have higher m(x). For example, a short loop that prints \"01\" yields outputs \"01\", \"0101\", \"010101\", etc., giving those strings relatively higher probabilities than a long, random-looking string.\n\n4) Formal definitions or rules\n- m(x) as above; K(x) (Kolmogorov complexity) is the length of the shortest program producing x on U, with m(x) ≈ 2^{-K(x)} up to a constant.\n\n5) Step-by-step justification or mechanism\n- Step 1: toss fair coins to form a program p. Step 2: run U on p. Step 3: output x = U(p). Step 4: m(x) collects the total weight 2^{-|p|} of all programs yielding x.\n\n6) Common misconceptions and clarifications\n- Not computable in general; depends on the chosen universal machine; the sum over all x is ≤ 1; relates to simplicity via K(x).\n\n7) One-sentence takeaway\n- Algorithmic probability formalizes a rigorous version of Occam’s razor: simpler outputs are more probable under a universal program-generation process.\n\nKey terms\n- Algorithmic probability: m(x), the chance a random program outputs x.\n- Prefix-free: no valid program is a prefix of another; ensures valid probability sums.\n- Kolmogorov complexity K(x): length of the shortest program producing x.\n- Universal prefix-free machine: a fixed model used to define m(x)."}
{"Major": "Artificial Intelligence", "Term": "behavior informatics (BI)", "Explanation": "1) High-level idea\n- BI studies how people and automated agents behave with information systems to understand, predict, and improve interactions and decisions.\n\n2) Precise definition\n- Behavior informatics is an interdisciplinary field that uses data-driven analysis, computational models, and information-processing methods to study behavior in information-rich settings, aiming to explain, predict, and guide action in systems and applications.\n\n3) Intuitive explanation and simple example\n- Example: analyzing a student’s online course logs (pages viewed, time on task, quiz attempts) to detect engagement patterns and tailor content or layout to boost learning outcomes.\n\n4) Formal definitions or rules\n- Core workflow: Data collection → Feature extraction → Modeling (patterns/sequences/user models) → Inference (predictions, insights) → Application (adaptive interfaces, recommendations).\n\n5) Step-by-step justification or mechanism\n- Collect telemetry from users/systems; preprocess and extract features; build and validate behavioral models; interpret results; feed insights back to improve the system.\n\n6) Common misconceptions and clarifications\n- Not just psychology; not only AI; privacy and ethics matter; focuses on patterns across groups or users, not every individual; complements human-computer interaction.\n\n7) Takeaway\n- BI turns behavior data into actionable insights to design smarter information systems.\n\nKey terms\n- Behavior: Actions of people or agents in an information setting.\n- Informatics: Using data and information processing to solve problems.\n- User modeling: Representing a user’s preferences or behavior.\n- Predictive analytics: Forecasting future actions or outcomes.\n- Human-computer interaction: Study of how people interact with technology; BI informs better design."}
{"Major": "Artificial Intelligence", "Term": "big data", "Explanation": " Big data explainer\n\n1) Concise high-level idea\n- Big data means data sets that are so large or complex that ordinary tools can’t process them efficiently, but which can yield valuable insights when analyzed with specialized methods.\n\n2) Precise definition\n- Big data: data collections that are high in volume and complexity, requiring advanced storage, processing, and analytics beyond traditional databases.\n\n3) Intuitive explanation and simple example\n- Intuition: think of streams of data from many sources that arrive fast and in many forms; you need new tech to store and analyze them in time.\n- Example: analyzing real-time transactions across millions of users to flag fraud as it happens.\n\n4) Formal definitions or rules\n- Volume: enormous data sizes (from gigabytes to exabytes).\n- Velocity: rapid generation and need for near-real-time processing.\n- Variety: multiple data types (text, images, logs, sensors).\n- Veracity/Value: data quality and usefulness for decisions.\n\n5) Step-by-step mechanism (brief)\n- Data is generated → stored across many machines → processed in parallel → insights guide actions.\n\n6) Common misconceptions and clarifications\n- More data isn’t automatically better; quality and relevant questions matter. Not every problem needs big data or complex tools.\n\n7) One-sentence takeaway\n- Big data is about using scalable tools to turn massive, fast, and varied data into actionable knowledge.\n\nKey terms\n- Big data: datasets too large/complex for ordinary tools; require new methods.\n- Volume: amount of data.\n- Velocity: speed of data generation/processing.\n- Variety: different data types.\n- Veracity/Value: data quality and usefulness."}
{"Major": "Artificial Intelligence", "Term": "convolutional neural network", "Explanation": "Convolutional Neural Network (CNN)\n\n1) High-level idea\n- A CNN recognizes patterns in images by sliding small filters to detect local features, then combines them through multiple layers to identify objects.\n\n2) Precise definition\n- A CNN is a neural network architecture for grid-like data (e.g., images) that uses convolutional layers with shared weights, followed by pooling and dense layers, trained end-to-end for tasks such as classification.\n\n3) Intuitive explanation and simple example\n- A small filter (stencil) slides across an image, multiplying and summing values to produce a feature map that highlights where that pattern appears. Stacking layers lets the network learn from edges to textures to shapes. Pooling then summarizes nearby results to reduce size.\n\n4) Formal definitions or rules\n- Convolution at position (i,j): output[i,j] = sum_{m,n} input[i+m, j+n] · kernel[m,n] + bias\n- Stride and padding adjust output size; activation adds nonlinearity (e.g., ReLU).\n\n5) Mechanism (step-by-step)\n- 1) Apply learnable filters to create feature maps\n- 2) Apply nonlinearity\n- 3) Pool to reduce spatial size\n- 4) Repeat with more filters\n- 5) Flatten and classify with dense layers\n\n6) Common misconceptions and clarifications\n- Not only for images; can process other grid-like data. Weights are shared across positions, reducing parameters.\n\n7) Takeaway (one-sentence)\n- CNNs are efficient, layered pattern detectors that learn to recognize patterns in images through local filtering and hierarchical composition.\n\nKey terms\n- Convolution: sliding-filter operation producing a feature map.\n- Filter/Kernel: small matrix that detects a pattern.\n- Feature map: result of a convolution layer.\n- Pooling: downsampling to reduce size.\n- Stride: step size of the filter."}
{"Major": "Artificial Intelligence", "Term": "Darkforest", "Explanation": "Sections\n\n1) High-level idea\n- DarkForest is a Go-playing artificial intelligence that combines neural networks with search to pick strong moves.\n\n2) Precise definition\n- DarkForest is a Go AI developed by Tencent AI Lab. It uses Monte Carlo Tree Search guided by neural networks to evaluate board positions and select moves.\n\n3) Intuitive explanation and simple example\n- Think of exploring possible moves as a tree. The AI simulates outcomes to estimate which moves win more often, while a neural network quickly says which areas of the board look promising. Example: if a move threatens a strong wall, the network may rate it highly and the search tests it more thoroughly.\n\n4) Formal definitions or rules\n- Monte Carlo Tree Search (MCTS): a loop of selecting a move, expanding the tree, simulating outcomes, and updating estimates.\n- Neural networks: models that produce (a) policy—probabilities over legal moves, and (b) value—estimated chance of winning from the position.\n\n5) Step-by-step mechanism\n- 1) Observe board state. 2) Run network-guided MCTS. 3) Choose the most visited move. 4) Update with new game information. 5) Repeat.\n\n6) Common misconceptions and clarifications\n- Not conscious or general AI; Go-specific; distinct from AlphaGo but shares ideas.\n\n7) One-sentence takeaway\n- DarkForest showcases how neural networks and search can create strong, Go-playing AI systems.\n\nKey terms\n- Go: 19x19 strategy board game.\n- Monte Carlo Tree Search (MCTS): search method using simulations to score moves.\n- Neural networks (policy/value): models that suggest move probabilities and win likelihood."}
