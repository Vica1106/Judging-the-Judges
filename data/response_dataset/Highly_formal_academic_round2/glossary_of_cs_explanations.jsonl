{"Major": "Computer Science", "Term": "quantum computing", "Explanation": "1) High-level idea\n- Quantum computing uses quantum bits to process information in ways that exploit superposition and entanglement, enabling some problems to be solved more efficiently than on classical computers.\n\n2) Precise definition\n- A quantum computer performs computation using quantum-mechanical systems (qubits) and is governed by unitary evolution and probabilistic measurement, enabling certain tasks via quantum algorithms.\n\n3) Intuitive explanation and simple example\n- A qubit can be in a blend of 0 and 1 simultaneously (a superposition). Two qubits can be entangled, meaning their results are linked. Think of a search: a quantum algorithm can amplify correct answers through interference, making them more likely to appear when measured.\n\n4) Formal definitions or rules\n- Qubit state: |ψ⟩ = α|0⟩ + β|1⟩ with |α|^2 + |β|^2 = 1.\n- Unitary gate: a reversible transformation U with U†U = I.\n- Measurement: yields |0⟩ with probability |α|^2 or |1⟩ with probability |β|^2.\n- Entanglement: multi-qubit states not factorizable into single-qubit states.\n\n5) Step-by-step mechanism\n- Prepare qubits → apply quantum gates → create interference via superposition/entanglement → measure to read outcomes.\n\n6) Common misconceptions and clarifications\n- Not all problems are faster; quantum speedups are problem-specific and sensitive to noise and error correction.\n\n7) Takeaway\n- Quantum computing harnesses quantum laws to tackle select tasks beyond classical reach.\n\nKey terms\n- Qubit: basic quantum information unit.\n- Superposition: simultaneous 0 and 1 states.\n- Entanglement: linked multi-qubit states.\n- Unitary gate: reversible quantum operation.\n- Measurement: reads a definite classical result."}
{"Major": "Computer Science", "Term": "big O notation", "Explanation": "Big O notation (student-friendly explainer)\n\n1) High-level idea\n- Big O measures how runtime or memory grows as input size n increases, ignoring constant factors and small inputs.\n\n2) Precise definition\n- f(n) ∈ O(g(n)) if ∃ constants c > 0 and n0 such that ∀ n ≥ n0, f(n) ≤ c·g(n).\n\n3) Intuition and simple example\n- Example: binary search takes about log2(n) steps → O(log n). A linear scan takes O(n). Doubling n roughly doubles the work.\n- Concept: we care about the dominant growth, not exact counts.\n\n4) Formal definitions / rules\n- Common growth bounds: O(1), O(log n), O(n), O(n log n), O(n^2).\n- Rules: drop constants and lower-order terms; if f(n) ≤ c·g(n) for large n, then f ∈ O(g(n)).\n\n5) Step-by-step justification (mechanism)\n- Identify a count f(n) of basic operations.\n- Pick a simple g(n) that bounds f(n) for large n.\n- Show constants c, n0 exist with f(n) ≤ c·g(n) for n ≥ n0.\n- Conclude f ∈ O(g(n)).\n\n6) Common misconceptions\n- Big O describes growth, not exact time; it’s an upper bound, not a precise runtime.\n\n7) Takeaway\n- Big O tells how costs scale with input size.\n\nKey terms\n- Big O notation: upper-bound growth rate.\n- Time complexity: f(n) for runtime.\n- Dominant term: fastest-growing part of f(n).\n- n: input size."}
{"Major": "Computer Science", "Term": "semantics", "Explanation": "High-level idea\n- Semantics is about the meaning or effects of programs, not just their written form.\n\nPrecise definition\n- Semantics assigns meaning to syntactic elements (programs)—mapping each construct to a mathematical object or to observable behavior.\n\nIntuitive explanation and simple example\n- If a language has numbers and plus, the program 3 + 4 has semantics equal to the number 7. Different programs that compute the same result have the same meaning (are equivalent). For input/output, print 5 has the meaning “output the value 5.”\n\nFormal definitions (brief)\n- Denotational semantics: every expression E is mapped to a mathematical meaning ⟦E⟧.\n- Operational semantics: execution is described by steps (configurations) that lead to a final result or observable effect.\n- Use: semantics allows formal reasoning about correctness and equivalence.\n\nMechanism (how it’s used)\n- Specify meanings for basic constructs, compose to get meanings for complex programs, then compare meanings to prove equivalence or correctness.\n\nCommon misconceptions\n- Semantics ≠ syntax; semantics is about what programs do, not how they are written.\n- Semantics may be partial or nondeterministic in some languages.\n\nOne-sentence takeaway\n- Semantics explains the true meaning and behavior of programs, enabling rigorous reasoning about their correctness and equivalence.\n\nKey terms\n- Semantics: meaning of programs\n- Syntax: structure/format of code\n- Denotational semantics: mathematical meaning mapping\n- Operational semantics: execution steps and state\n- Correctness: program meets its specification"}
{"Major": "Computer Science", "Term": "floating-point arithmetic", "Explanation": "1) High-level idea\n- Floating-point arithmetic stores numbers with a fixed number of binary digits using scientific notation, giving a wide range with finite precision.\n\n2) Precise definition\n- A floating-point number has sign, exponent, and significand. Value = (-1)^sign × (1.fraction) × 2^(exponent − bias). IEEE 754 specifies the bit layout, bias, and rules.\n\n3) Intuition and simple example\n- Example: 6.75₂ = 110.11₂ = 1.1011₂ × 2². Sign=0, exponent encodes 2, fraction stores 1011. Decimal 0.1 is not exact in binary; it’s approximated.\n\n4) Formal rules\n- Normalization: mantissa in [1,2). Finite precision limits digits. Rounding to nearest (ties to even). Exponent bias. Special values (Inf, NaN).\n\n5) Mechanism (step-by-step)\n- Steps: align exponents, add/subtract significands, normalize result, round to fit, handle overflow/underflow and sign.\n\n6) Common misconceptions\n- Not all real numbers are exact; rounding yields error. Sums may behave oddly (cancellation). 0.1 + 0.2 may differ from 0.3.\n\n7) Takeaway\n- Floating-point is an efficient, finite-precision way to approximate real numbers; errors come from rounding.\n\nKey terms\n- Floating-point number: real numbers represented with sign, exponent, and significand in finite precision.\n- Mantissa/ significand: the significant digits (1.fraction) of the number.\n- Exponent: scales magnitude; stored with a bias.\n- Rounding mode: rule for choosing the nearest representable value.\n- Machine epsilon: the smallest difference between 1 and the next representable number."}
{"Major": "Computer Science", "Term": "quicksort", "Explanation": "1) High-level idea\n- Quicksort sorts by picking a pivot, dividing the list into items ≤ pivot and > pivot, and recursively sorting the parts.\n\n2) Precise definition\n- Quicksort is a comparison-based in-place sorting algorithm. It selects a pivot, partitions the array so elements left of the pivot are ≤ it and elements right are > it, recursively sorts the subarrays, and concatenates results.\n\n3) Intuitive explanation and simple example\n- Think of organizing a deck by placing a chosen pivot card, moving smaller cards to the left and larger to the right, then sorting the left and right stacks.\n- Example: [3,6,2,8,5], choose pivot 5 → [3,2,5,6,8]; left [3,2] sorts to [2,3], final [2,3,5,6,8].\n\n4) Formal definitions or rules\n- Partition(A, low, high):\n  - pivot = A[high]; i = low\n  - for j from low to high-1: if A[j] ≤ pivot, swap A[i], A[j], i++\n  - swap A[i], A[high]; return i\n- Quicksort(A, low, high):\n  - if low < high: p = Partition(A, low, high); Quicksort(A, low, p-1); Quicksort(A, p+1, high)\n\n5) Step-by-step mechanism (no chain-of-thought)\n- Choose a pivot\n- Partition the array around it\n- Recursively sort left and right subarrays\n- Combine by the array being in sorted order\n\n6) Common misconceptions and clarifications\n- Not always linear or stable; worst-case time is O(n^2) (e.g., poor pivot choices); in-place variants use little extra memory; stability is not guaranteed unless special variants are used.\n\n7) Takeaway\n- Quicksort sorts by iterative partitioning around a pivot and recursive sorting of subarrays.\n\nKey terms\n- Pivot: chosen element around which partitioning occurs.\n- Partition: reorders so left side ≤ pivot and right side > pivot; returns pivot’s final index.\n- In-place: sorting with negligible extra memory beyond the array and recursion.\n- Average-case: O(n log n). Worst-case: O(n^2)."}
{"Major": "Computer Science", "Term": "agent-based model (ABM)", "Explanation": "Agent-based model (ABM)\n\n- High-level idea\n  - Simulate many individual decision-makers (agents) with simple rules to see global system patterns.\n\n- Definition\n  - An ABM is a computational model consisting of autonomous agents that interact with each other and their environment, producing system-level behavior from local rules.\n\n- Intuition and example\n  - Example: pedestrians in a corridor. Each person follows simple rules (avoid collisions, head toward a destination). From many individuals, crowd flow and congestion emerge.\n\n- Formal definitions / rules\n  - Agent: autonomous entity with state (e.g., position, speed) and behavior rules.\n  - Environment: space where agents move and interact (grid or continuous).\n  - Rules: local, possibly probabilistic decisions based on nearby agents or environment.\n  - Emergence: global patterns arise without central control.\n  - Time: discrete steps or continuous time; update may be synchronous or asynchronous.\n\n- Mechanism (step-by-step)\n  - Initialize agents and environment.\n  - For each step: agents observe local state, apply rules, update states/locations.\n  - Environment updates if needed; collect statistics.\n  - Repeat until stop condition.\n\n- Common misconceptions\n  - ABMs are just simulations; they are models to test hypotheses.\n  - Results depend on chosen rules; realism varies.\n  - Deterministic vs. stochastic: both are possible.\n\n- Takeaway\n  - ABMs reveal how simple local rules can generate complex, real-world macro behavior.\n\n- Key terms\n  - Agent: autonomous decision-maker.\n  - Environment: space where agents act.\n  - Emergence: global patterns from local interactions.\n  - Local interaction: decisions based on nearby agents/environment.\n  - Heterogeneity: differences among agents."}
{"Major": "Computer Science", "Term": "big data", "Explanation": "1) High-level idea\n- Big data means data sets that are too large or complex for standard tools, but can yield useful insights when processed at scale.\n\n2) Precise definition\n- Big data refers to data sets with large Volume, high Velocity, and varied Variety (the 3Vs; sometimes including Veracity and Value) that require distributed storage and parallel processing.\n\n3) Intuitive explanation and simple example\n- Example: billions of social media posts and sensor readings arriving every second. Scalable storage and parallel analysis let us detect trends in near real time.\n\n4) Formal definitions or rules\n- 3Vs: Volume (amount of data), Velocity (speed of arrival), Variety (different data types/formats). Veracity (trustworthiness) and Value (useful insights) are commonly added refinements.\n\n5) Step-by-step mechanism\n- Collect data from many sources → store in distributed systems → process with parallel frameworks → analyze and visualize to extract insights.\n\n6) Common misconceptions and clarifications\n- Not just “a lot of data.” Also about speed and diversity; not only for tech giants—many sectors use big data tools.\n\n7) Takeaway\n- Big data is about scalable methods that turn massive, fast, varied data into actionable knowledge.\n\nKey terms\n- Big data: extremely large, fast-moving, and diverse data sets needing special processing.\n- Volume: amount of data.\n- Velocity: speed of data in/out.\n- Variety: different data types and formats.\n- Analytics: methods for deriving insights from data."}
{"Major": "Computer Science", "Term": "class", "Explanation": "1) High-level idea\n- A class is a blueprint for creating objects that share a type, data, and behavior.\n\n2) Precise definition\n- In object-oriented programming, a class defines a new type by bundling attributes (data) and methods (functions) that operate on that data; objects (instances) are created from the class.\n\n3) Intuitive explanation and simple example\n- Think of a Car class as a template: it specifies properties like color and speed and actions like drive. You can create objects like myCar = Car('red') and then call myCar.drive(10).\n\n4) Formal definitions or rules\n- A class groups data (attributes/fields) and behavior (methods) that act on that data.\n- Each object has its own state (values of attributes) but shares the class’s methods.\n- Methods are functions defined inside the class; they usually take the object as a parameter (e.g., self or this).\n- Access control varies by language (public/private), but the idea of encapsulation remains.\n\n5) Step-by-step mechanism\n- Define the class.\n- Instantiate objects from the class.\n- Each object holds its own state.\n- Use methods to read or modify that state.\n\n6) Common misconceptions and clarifications\n- Not the same as an object; it is the template.\n- It’s not only for data; it also defines behavior.\n- Some languages use prototype-based or other approaches, but the class idea is a common pattern.\n\n7) Takeaway\n- A class is a blueprint for creating objects that bundle data and behavior.\n\nKey terms\n- class: blueprint for a type.\n- object/instance: a concrete product created from a class.\n- attribute/field: stored data on an object.\n- method: function defined in a class that operates on an object.\n- encapsulation: combining data and behavior in one unit and hiding internal details."}
{"Major": "Computer Science", "Term": "coding theory", "Explanation": "1) High-level idea\n- Coding theory studies how to send data reliably by adding redundancy (codes) so a noisy channel can reveal and fix errors.\n\n2) Precise definition\n- It is the mathematical study of designing codes for reliable transmission and storage, focusing on distances between codewords and how to recover data after errors.\n\n3) Intuitive explanation and simple example\n- If you send 1011 with a parity bit to enforce even parity, yielding 10110, a receiver that gets 10100 will see a parity mismatch and know an error occurred; more advanced codes can also locate and correct the error.\n\n4) Formal definitions or rules\n- Code: a set of codewords.\n- Encoding: map data to a codeword.\n- Decoding: infer the most likely original codeword from a received word.\n- Hamming distance d(x,y): number of positions where x and y differ.\n- Minimum distance d_min: smallest distance between distinct codewords.\n- A code with d_min detects up to d_min−1 errors and corrects up to floor((d_min−1)/2) errors.\n\n5) Mechanism (step-by-step)\n- Encode data to a codeword.\n- Transmit over a noisy channel.\n- Receive possibly corrupted word.\n- Decode to the nearest codeword (or signal an error).\n\n6) Common misconceptions and clarifications\n- More redundancy helps, but reduces efficiency.\n- Parity checks detect only some errors (often just odd/even).\n- Larger d_min helps but increases overhead.\n\n7) Takeaway (one-sentence)\n- Coding theory analyzes how to balance redundancy and reliability to protect information from errors.\n\nKey terms\n- Code: set of codewords.\n- Hamming distance: number of differing positions.\n- Parity: a simple check bit for even/odd total.\n- Minimum distance: smallest distance between codewords; governs error tolerance."}
{"Major": "Computer Science", "Term": "computability theory", "Explanation": "1) High-level idea\n- Computability theory asks which tasks can be solved by a purely mechanical procedure (an algorithm), in principle.\n\n2) Precise definition\n- Computable function: there exists a Turing machine that, on any input, halts with the correct output.\n- Decidable problem: a machine halts on every input and answers yes or no correctly.\n- Semi-decidable (recursively enumerable): a machine halts and accepts yes-instances, but may loop on others.\n\n3) Intuition and simple example\n- Examples: addition, sorting, and many numerical tasks are computable.\n- The halting problem is not computable: no general machine decides for all programs-input pairs whether they halt.\n\n4) Formal definitions or rules\n- Turing machine: a finite-state controller, an infinite tape, and a read/write head; computation proceeds by fixed transition rules.\n\n5) Mechanism (how it works)\n- To prove computable: give a machine that implements the algorithm.\n- To prove noncomputable: reduce a known noncomputable problem (e.g., Halting) to the task or use diagonalization.\n\n6) Misconceptions and clarifications\n- Computable ≠ fast; some computable tasks are impractically slow.\n- Not all problems are computable; some are undecidable.\n- Different models (Turing machines, lambda calculus) capture the same class of computable problems (Church–Turing).\n\n7) Takeaway\n- Computability theory separates algorithmically solvable tasks from those that are inherently unsolvable.\n\nKey terms\n- Computable function: solvable by an algorithm.\n- Turing machine: the standard abstract computation model.\n- Decidable problem: always halts with a correct yes/no answer.\n- Semi-decidable: halts on yes-instances, possibly not on others.\n- Church–Turing thesis: all reasonable models compute the same class of functions."}
