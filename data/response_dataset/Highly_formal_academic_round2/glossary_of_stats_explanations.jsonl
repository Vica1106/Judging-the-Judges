{"Major": "Statistics", "Term": "mutual independence", "Explanation": "1) High-level idea\n- Mutually independent events do not influence each other; the joint likelihood equals the product of individual chances for every group.\n\n2) Precise definition\n- Let A1, A2, ..., Ak be events. They are mutually independent if for every subset I ‚äÜ {1,...,k},\n  P(‚à©_{i‚ààI} A_i) = ‚àè_{i‚ààI} P(A_i).\n\n3) Intuition and a simple example\n- Intuition: Knowing any combination of outcomes does not change the probability of any other outcome.\n- Example: Three fair coin tosses. A1 = ‚Äútoss 1 is heads,‚Äù A2 = ‚Äútoss 2 is heads,‚Äù A3 = ‚Äútoss 3 is heads.‚Äù Then for any subset, P(‚à© A_i) = (1/2)^{|I|} = ‚àè P(A_i).\n\n4) Formal definitions or rules\n- Check all subsets I of {1,...,k}; equality must hold for each nonempty I (and P(‚àÖ)=1 by convention).\n\n5) Step-by-step justification (mechanism)\n- For each subset I, compute P(‚à©_{i‚ààI} A_i). Compare to ‚àè_{i‚ààI} P(A_i). If equal for all I, mutual independence holds; otherwise not.\n\n6) Common misconceptions and clarifications\n- Mutual independence implies pairwise independence; not vice versa.\n- Disjoint events are not independent in general (except trivial zero-probability cases).\n\n7) Takeaway\n- Mutual independence means every group of events behaves like independent trials, with joint probability equal to the product of individual probabilities.\n\nKey terms\n- Mutual independence: joint probabilities factorize for all subsets.\n- Independence: events do not affect each other; product rule for intersections.\n- Joint distribution: probabilities of all combinations of events.\n- Events: outcomes or sets of outcomes in a probability space.\n- Product rule: the probability of the intersection of independent events equals the product of their probabilities."}
{"Major": "Statistics", "Term": "statistical inference", "Explanation": "1) High-level idea\n- Use a sample to learn about a larger population, while explicitly measuring uncertainty.\n\n2) Precise definition\n- Statistical inference is the process of using sample data to estimate population parameters or to test ideas about the population, with uncertainty quantified by probability.\n\n3) Intuition and an example\n- Intuition: samples are noisy but informative about the whole group; we summarize evidence and say how sure we are.\n- Example: polling 1,000 voters to estimate overall support for a candidate. The estimate comes with a margin of error and a confidence level (e.g., 95%).\n\n4) Formal definitions or rules\n- Population: the entire group of interest.\n- Sample: the observed subset from the population.\n- Parameter: the true, unknown value describing the population.\n- Estimator: a rule that turns sample data into an estimate of a parameter (e.g., sample mean).\n- Confidence interval: a range built from the data that, with a stated probability, contains the true parameter.\n\n5) Step-by-step mechanism\n- Define the parameter of interest.\n- Collect a representative sample.\n- Compute an estimator from the data.\n- Quantify uncertainty (e.g., construct a confidence interval).\n\n6) Common misconceptions\n- Inference guarantees certainty: it only provides probabilistic statements.\n- A sample is identical to the population; it‚Äôs an approximation.\n- A wide interval means no information; it reflects true variability.\n\n7) Takeaway\n- Statistical inference translates sample evidence into learned statements about a population, with explicit, quantifiable uncertainty.\n\nKey terms\n- Population: the group of interest.\n- Sample: observed subset.\n- Parameter: true population value.\n- Estimator: rule to estimate a parameter from data.\n- Confidence interval: range likely to contain the parameter with specified probability."}
{"Major": "Statistics", "Term": "joint distribution", "Explanation": "1) High-level idea\n- The joint distribution describes how two or more random variables behave together, capturing all possible pairs (or tuples) and their probabilities or densities.\n\n2) Precise definition\n- Discrete: P(X=x, Y=y) for all x,y; sums to 1.\n- Continuous: joint pdf f_{X,Y}(x,y) with ‚à´‚à´ f_{X,Y}(x,y) dx dy = 1.\n- Marginals: P(X=x)=‚àë_y P(X=x,Y=y); f_X(x)=‚à´ f_{X,Y}(x,y) dy.\n\n3) Intuition and simple example\n- Intuition: tells you how likely any combination of values is.\n- Example: X = result of coin flip (H/T), Y = roll of a die (1‚Äì6). The joint distribution gives probabilities for every (X,Y) pair; if independent, P(H, k)=0.5*(1/6).\n\n4) Formal definitions or rules\n- Joint to marginal: P(X=x)=‚àë_y P(X=x,Y=y); f_X(x)=‚à´ f_{X,Y}(x,y) dy.\n- Conditional: P(Y=y|X=x)=P(X=x,Y=y)/P(X=x); f_{Y|X}(y|x)=f_{X,Y}(x,y)/f_X(x).\n- Independence: P(X=x, Y=y)=P(X=x)P(Y=y) for all x,y; or f_{X,Y}(x,y)=f_X(x)f_Y(y).\n\n5) Quick mechanism\n- Identify variables, write joint, obtain marginals by summing/integrating, check independence via product of marginals, derive conditional by division.\n\n6) Common misconceptions\n- Joint ‚â† product of marginals unless independent.\n- Continuous vs discrete formulas differ (densities vs probabilities).\n\n7) Takeaway\n- The joint distribution is the full description of how two variables co-occur.\n\nKey terms\n- Joint distribution: probabilities/densities of value pairs.\n- Marginal distribution: distribution of a single variable.\n- Conditional distribution: distribution of one variable given another.\n- Independence: joint equals product of marginals.\n- Random variables: variables representing outcomes of random processes."}
{"Major": "Statistics", "Term": "random variable", "Explanation": "1) High-level idea\n- A random variable is a function that assigns a number to each outcome of a random process, turning uncertainty into numerical data.\n\n2) Definition\n- X: Œ© ‚Üí ‚Ñù is a measurable function on a probability space (Œ©, F, P).\n- For discrete X: P(X = x) = ‚àë P(œâ) over œâ with X(œâ) = x.\n- Distribution function: F_X(x) = P(X ‚â§ x).\n\n3) Intuition and simple example\n- Example: Roll a fair die. Œ© = {1,2,3,4,5,6}, X(œâ)=œâ. Then P(X=k)=1/6 for k=1,‚Ä¶,6. The values X can take describe the outcome numerically.\n\n4) Formal definitions or rules\n- Moments: E[X] = ‚àë x P(X=x) (discrete) or ‚à´ x f_X(x) dx (continuous).\n- CDF: F_X(x) = P(X ‚â§ x).\n\n5) How it works (brief mechanism)\n- Specify the underlying random process (Œ©, F, P); define X to map outcomes to numbers; use P to describe X‚Äôs distribution and compute summaries (mean, variance, etc.).\n\n6) Common misconceptions\n- It‚Äôs not the actual outcome itself (that‚Äôs in Œ©). It‚Äôs a numeric function describing outcomes; it may be discrete or continuous.\n\n7) Takeaway\n- A random variable is a number-valued mapping that captures the distribution of a random process.\n\nKey terms\n- Random variable: number-valued function of outcomes.\n- Sample space: set of all possible outcomes.\n- Probability space: (Œ©, F, P) describing randomness.\n- Distribution: probabilities of X‚Äôs values (or cumulative probabilities).\n- Expectation: average value of X under its distribution."}
{"Major": "Statistics", "Term": "confidence interval (CI)", "Explanation": "Confidence Interval (CI)\n\n- High-level idea\n  - A CI is a plausible range for the true value we want to estimate, based on sample data.\n\n- Precise definition\n  - For a parameter Œ∏, a (1-Œ±) confidence interval [L(X), U(X)] is constructed so that, over many repetitions of the study, the interval contains Œ∏ with probability at least 1-Œ±.\n\n- Intuition and a simple example\n  - If we repeated the study many times, about 95% of the CIs would cover the true mean. Example: estimate a mean, then form mean ¬± (critical value) √ó (standard error).\n\n- Formal definition/rules\n  - L(X) = estimate ‚àí c √ó SE, U(X) = estimate + c √ó SE, where c is the critical value for the desired level (e.g., z* or t* for 1-Œ±).\n\n- Step-by-step mechanism\n  - Collect data; compute estimate and standard error; choose the critical value; form the interval; interpret as the long-run coverage.\n\n- Common misconceptions\n  - It does not say the probability the true value lies in this one interval; it refers to long-run frequency over repeated samples.\n  - A higher level or larger SE widens the interval; larger samples tighten it.\n\n- Takeaway (one sentence)\n  - A confidence interval gives a data-based range that, in the long run, would capture the true parameter most of the time if we repeated the study.\n\nKey terms\n- Confidence interval: a range derived from data likely to cover the true parameter in repeated samples.\n- Confidence level: the long-run proportion of intervals that would cover the parameter (e.g., 95%).\n- Margin of error: half the interval width.\n- Standard error: an estimate of how much the statistic varies across samples.\n- Parameter: the true quantity being estimated (e.g., true mean)."}
{"Major": "Statistics", "Term": "covariance", "Explanation": "1) High-level idea\n- Covariance measures whether two variables tend to move together: positive covariance means they rise together, negative means one tends to rise while the other falls.\n\n2) Precise definition\n- Population: Cov(X,Y) = E[(X ‚àí Œºx)(Y ‚àí Œºy)]\n- Sample: CovÃÇ(X,Y) = (1/(n‚àí1)) Œ£i (xi ‚àí xÃÑ)(yi ‚àí »≥)\n\n3) Intuition and simple example\n- Example: (1,2), (2,4), (3,6)\n  - xÃÑ = 2, »≥ = 4; deviations: (‚àí1,0,1) and (‚àí2,0,2)\n  - Products: 2, 0, 2; sum = 4; CovÃÇ = 4/(3‚àí1) = 2\n  - Interpretation: when X is above its average, Y tends to be above its average (positive covariance).\n\n4) Formal definitions or rules\n- Covariance can be positive, negative, or zero. It depends on units; larger scales change its magnitude.\n- Relation to correlation: Correlation œÅ = Cov(X,Y) / (œÉx œÉy)\n\n5) Step-by-step mechanism\n- Center each variable by its mean\n- Multiply corresponding centered values\n- Average the products (divide by n‚àí1 for a sample)\n\n6) Common misconceptions and clarifications\n- Not the same as correlation; covariance isn‚Äôt standardized\n- Zero covariance does not necessarily mean independence\n- Covariance depends on the units of X and Y\n\n7) Takeaway (one sentence)\n- Covariance signals the direction of joint variation between two variables, and correlation standardizes that signal.\n\nKey terms\n- Covariance: measure of how two variables vary together\n- Correlation: standardized covariance\n- Population vs. sample covariance: true vs. estimated from data\n- Deviation: xi ‚àí xÃÑ or yi ‚àí »≥\n- Independence: variables with zero covariance need not be independent\n\n"}
{"Major": "Statistics", "Term": "likelihood function", "Explanation": "Likelihood function\n\n1) High-level idea\n- The likelihood function tells us which parameter values make the observed data most plausible under a chosen model.\n\n2) Precise definition\n- If x1,...,xn are independent draws from a distribution with density or PMF f(x|Œ∏), the likelihood function is L(Œ∏; x) = ‚àè_{i=1}^n f(xi|Œ∏). It is a function of Œ∏ (the parameter), given the observed data x.\n\n3) Intuition and a simple example\n- Intuition: for each Œ∏, L(Œ∏) weighs how likely the observed data are if Œ∏ were the true value.\n- Example: flipping a coin with unknown p of heads. If k heads in n flips are observed, L(p) = p^k (1‚àíp)^{n‚àík}. The p that maximizes L is pÃÇ = k/n (the MLE).\n\n4) Formal definitions or rules\n- Log-likelihood: ‚Ñì(Œ∏) = log L(Œ∏; x) = ‚àë_{i=1}^n log f(xi|Œ∏).\n- If X_i are i.i.d., maximize ‚Ñì(Œ∏) (often easier than L(Œ∏)) to obtain the Maximum Likelihood Estimator (MLE).\n\n5) Step-by-step mechanism\n- Specify model f(x|Œ∏); compute L(Œ∏; x); take logs to get ‚Ñì(Œ∏); find Œ∏ÃÇ that maximizes ‚Ñì (or L); interpret Œ∏ÃÇ as the estimate.\n\n6) Common misconceptions and clarifications\n- Not P(Œ∏|x) or P(Œ∏); it‚Äôs a function of Œ∏ for fixed data.\n- L is not a probability value; Œ∏ is treated as the variable.\n\n7) Takeaway\n- The likelihood connects model parameters to the observed data, guiding parameter estimation.\n\nKey terms\n- Likelihood function: Function of Œ∏ reflecting how plausible the data are under Œ∏.\n- Data: Observed values x1,...,xn.\n- Parameter: Œ∏ describing the model.\n- Maximum Likelihood Estimator (MLE): Œ∏ maximizing L(Œ∏; x).\n- Log-likelihood: ‚Ñì(Œ∏) = log L(Œ∏; x), easier to work with."}
{"Major": "Statistics", "Term": "probability measure", "Explanation": "1) High-level idea\n- A probability measure is the rule that assigns a number between 0 and 1 to events, in a way that respects how events combine.\n\n2) Precise definition\n- Let Œ© be the set of all outcomes, and ùîΩ a collection of subsets of Œ© (the events), closed under complements and countable unions (a sigma-algebra).\n- A function P: ùîΩ ‚Üí [0,1] is a probability measure if:\n  - P(Œ©) = 1 (normalization)\n  - For any countable collection {A_i} of pairwise disjoint sets in ùîΩ, P(‚à™i A_i) = ‚àëi P(A_i) (countable additivity)\n- Note: P(‚àÖ) = 0 follows from these rules.\n\n3) Intuition and simple example\n- Intuition: P(A) behaves like ‚Äúhow likely is A to happen,‚Äù and the probabilities add up correctly for disjoint possibilities.\n- Example: In a fair coin toss, Œ©={H,T}, ùîΩ = {‚àÖ,{H},{T},{H,T}}. P({H})=0.5, P({T})=0.5, P({H,T})=1.\n\n4) Formal rules\n- Non-negativity: P(A) ‚â• 0 for all A ‚àà ùîΩ.\n- Additivity: disjoint union of events sums their probabilities.\n- Normalization: P(Œ©)=1.\n\n5) Mechanism\n- To compute P(A), break A into disjoint pieces A = ‚à™i A_i, then sum P(A_i). For complex A, use finite unions and limits (where needed).\n\n6) Common misconceptions\n- Not all functions to [0,1] are probability measures.\n- P(A)=1 means A occurs almost surely, not necessarily every single trial, unless Œ©\\A has probability 0 in the model.\n\n7) Takeaway\n- A probability measure is a principled way to assign consistent likelihoods to outcomes and their unions. \n\nKey terms\n- Probability measure: function with P(Œ©)=1 and additivity for disjoint events.\n- Sample space (Œ©): set of all possible outcomes.\n- Event: a well-defined subset of Œ©.\n- Sigma-algebra (ùîΩ): collection of events closed under complements and countable unions.\n- Almost surely: event with probability 1."}
{"Major": "Statistics", "Term": "regression analysis", "Explanation": "Section: High-level idea\n- Regression analysis models how a response variable changes when one or more predictors change, by estimating a mathematical relationship.\n\nSection: Precise definition\n- It‚Äôs a statistical method that models Y (response) as a function of X1,...,Xp (predictors), typically by fitting a line or curve that minimizes the difference between observed and predicted Y (the residuals).\n\nSection: Intuitive explanation and simple example\n- Example: predicting exam score (Y) from hours studied (X). More study often raises score; the model fits a line Y ‚âà Œ≤0 + Œ≤1X so you can predict scores from hours studied.\n\nSection: Formal definitions or rules\n- Simple linear regression: Y = Œ≤0 + Œ≤1X + Œµ, with E[Œµ]=0 and constant variance. Estimate Œ≤0, Œ≤1 by least squares. Assess fit with R-squared, confidence intervals, p-values; check assumptions: linearity, independence, homoscedasticity, normal errors.\n\nSection: Step-by-step justification or mechanism\n- Steps: collect data; choose model; estimate coefficients by minimizing sum of squared residuals; evaluate fit and assumptions; use the model for prediction or understanding relationships.\n\nSection: Common misconceptions and clarifications\n- Does not prove causation; beware extrapolation; outliers can distort results; correlation ‚â† causation; ensure appropriate model form.\n\nSection: Takeaway (one sentence)\n- Regression provides a quantified, data-driven way to predict and interpret how a response changes with predictors by fitting the best-possible relationship.\n\nKey terms\n- Regression: modeling relationships between a response and predictors.\n- Predictor: the independent variable(s) used to explain the response.\n- Response: the dependent variable being predicted or explained.\n- Least squares: method to fit the model by minimizing squared errors.\n- R-squared: measure of how much of the variability in the response is explained by the model."}
{"Major": "Statistics", "Term": "causal study", "Explanation": "1) Concise high-level idea\n- A causal study asks whether changing a factor (the treatment) causes a change in an outcome.\n\n2) Precise definition\n- A causal study estimates the causal effect of a treatment or exposure on an outcome, ideally by isolating the treatment from other factors. The gold standard is a randomized controlled trial.\n\n3) Intuitive explanation and simple example\n- Example: Does extra study time cause higher test scores? Randomly assign students to study more vs. standard study time; compare average scores.\n\n4) Formal definitions or rules\n- Causal effect for a unit: Y(1) ‚àí Y(0) (outcome if treated minus if not). Average Treatment Effect (ATE): E[Y(1) ‚àí Y(0)]. In randomized trials, the difference in average outcomes between treated and control estimates the ATE, given no interference and proper randomization. In observational data, methods are needed to adjust for confounding.\n\n5) Step-by-step justification or mechanism\n- Randomize to remove confounding ‚Üí measure outcomes ‚Üí compute difference in averages ‚Üí attribute difference to the treatment.\n\n6) Common misconceptions and clarifications\n- Correlation does not imply causation. Observational studies can indicate causality only with strong methods to address confounding; randomization provides stronger evidence.\n\n7) One-sentence takeaway\n- A causal study seeks to quantify how a specific intervention would change an outcome.\n\nKey terms\n- Causality: the relationship where one factor directly affects another.\n- Treatment: the factor or intervention being tested.\n- Outcome: what is measured to assess impact.\n- Randomization: assigning treatment by chance to equalize groups.\n- Confounding: other factors that create false or distorted treatment effects."}
