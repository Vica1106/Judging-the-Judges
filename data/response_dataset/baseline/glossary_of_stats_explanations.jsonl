{"Major": "Statistics", "Term": "mutual independence", "Explanation": "Mutual independence is a strong form of independence for several events. A1, A2, ..., An are mutually independent if every time you look at any subset of them, the probability that all of those events happen equals the product of their individual probabilities. In plain terms: knowing that some events occurred does not change the chances of any other events, and this holds for any combination.\n\nFormally, for any subset S of {1,...,n}, P(all events in S occur) = product of P(Ai) for i in S.\n\nExample: Take three fair coin flips. Let A be “first is heads,” B “second is heads,” C “third is heads.” Then:\n- P(A∩B) = 1/4 = P(A)P(B)\n- P(A∩B∩C) = 1/8 = P(A)P(B)P(C)\nSo A, B, C are mutually independent.\n\nNote: Mutual independence is stronger than pairwise independence. You can have events that are pairwise independent but not mutually independent."}
{"Major": "Statistics", "Term": "statistical inference", "Explanation": "Statistical inference is the process of drawing conclusions about a larger group (the population) from information you collect from a smaller group (the sample). Since you can’t measure everyone, you use data and probability to estimate what’s true for the whole population and to judge how confident you are in that estimate.\n\nThere are two main ideas: estimation and hypothesis testing. Estimation answers questions like “What is the likely average income of all adults in this city?” and gives a number plus a margin of error (a confidence interval). Hypothesis testing asks whether there is evidence for a claim, such as “Is more than half of people in this city in favor of option A?” and reports a result called a p-value that helps you decide if the claim is plausible.\n\nKey points: samples should be random and unbiased, because inference relies on the data representing the population. Inference always involves uncertainty—you’re making probabilistic statements about the population, not certainties about the sample you studied."}
{"Major": "Statistics", "Term": "joint distribution", "Explanation": "Joint distribution describes how two random variables behave together. It tells you the chances of every possible combination of their values.\n\n- Discrete case: If X and Y take specific values, the joint distribution is a table p(x,y) = P(X = x, Y = y). All entries sum to 1. You can get the margin (P(X = x)) by summing over y, and the conditional (P(Y = y | X = x)) by dividing p(x,y) by P(X = x).\n- Continuous case: If X and Y are continuous, their joint distribution is a joint density f(x,y). Probabilities come from areas: P(a ≤ X ≤ b, c ≤ Y ≤ d) = ∫∫ f(x,y) dx dy. Marginals and conditionals are found by integrating or dividing, just like in the discrete case.\n\nWhy it matters: It captures the relationship between the variables. If X and Y are independent, the joint distribution factors into the product of their marginals: p(x,y) = p_X(x) p_Y(y) (or f(x,y) = f_X(x) f_Y(y)). Example: outcomes of rolling two dice give a simple joint distribution where each pair (i,j) has probability 1/36."}
{"Major": "Statistics", "Term": "random variable", "Explanation": "A random variable is a way to turn a random process into numbers. It’s not just a plain variable you pick; it’s a function that assigns a specific number to each possible outcome of an experiment.\n\n- How it works: Take all possible results of an experiment as the \"outcomes.\" The random variable X assigns a number to each outcome. For example, when rolling a six-sided die, let X be the value shown. X can be 1, 2, 3, 4, 5, or 6, each with probability 1/6.\n- Types: Discrete random variables take countable values (0, 1, 2, …). Continuous random variables can take any value in an interval (like height or time).\n- Why it’s useful: The distribution of a random variable summarizes how likely each value is. You can talk about the average (expected value) and how spread out the values are (variance).\n\nIn short: a random variable translates outcomes of randomness into numbers, so we can analyze and compare them using numbers."}
{"Major": "Statistics", "Term": "confidence interval (CI)", "Explanation": "Confidence interval (CI) is a range of numbers you get from sample data to estimate a population value (like the true average). It comes with a confidence level, usually 95%. The idea: if you could repeat the study many times, and compute a CI from each sample, about 95% of those intervals would contain the true population value.\n\nFor your one study, the interval either contains the true value or it doesn’t—we don’t know which. The 95% reflects the method’s long-run success rate, not a probability about this single interval.\n\nThe interval is centered on your sample estimate (e.g., the sample mean) and widened by the margin of error. The margin of error depends on sample size and how variable the data are: more data and less variability give a narrower CI; a higher confidence level (like 99%) gives a wider CI."}
{"Major": "Statistics", "Term": "covariance", "Explanation": "Covariance is a measure of how two things change together. If X and Y tend to be high or low at the same time, they have positive covariance. If one tends to be high when the other is low, they have negative covariance. If they don’t show any linear pattern, the covariance is close to zero. Note: the size of the covariance depends on the units of X and Y, so it’s not easily comparable across different pairs.\n\nMath quick version:\n- Population: Cov(X,Y) = E[(X − E[X])(Y − E[Y])]\n- Sample: Cov(X,Y) = sum[(xi − x̄)(yi − ȳ)] / (n − 1)\n\nFor comparison, the correlation coefficient r is the standardized version: Cov(X,Y) divided by (SD(X)·SD(Y)), giving a unitless value between −1 and 1. Covariance is used in stats and finance to describe joint variability, such as how asset returns move together."}
{"Major": "Statistics", "Term": "likelihood function", "Explanation": "Likelihood function\n\nThe likelihood function tells you how likely your observed data are for different values of a parameter in a statistical model. It’s a function of the parameter θ, not of the data, once you’ve fixed the data you’ve actually seen.\n\n- Definition: L(θ) = P(data | θ) for discrete data, or f(data | θ) for continuous data.\n- Idea: Among all possible θ, which makes the observed data most probable? The θ that maximizes L(θ) is called the maximum likelihood estimate (MLE).\n- Independence: If data points are independent, the likelihood multiplies individual probabilities, turning into a product.\n- Practical use: We often work with the log-likelihood, log L(θ), because summing is easier than multiplying.\n- Note: The likelihood is not a probability distribution over θ itself (unless you add a prior, as in Bayesian analysis).\n\nExample: flipping a coin N times and seeing k heads. L(p) = p^k (1-p)^{N-k}. The MLE is p̂ = k/N."}
{"Major": "Statistics", "Term": "probability measure", "Explanation": "Probability measure: a rule that assigns a number between 0 and 1 to events in a random situation. An event is a set of outcomes you care about. The rule must satisfy: the whole set of outcomes has probability 1, the empty set has probability 0, and if events don’t overlap, the probability of “A or B” is P(A) + P(B). More generally, for any list of disjoint events, the probability that one of them occurs is the sum of their probabilities. It also respects containment: if A is contained in B, then P(A) ≤ P(B). This rule describes how probability mass is distributed over possible outcomes. Examples: for a fair coin, P({Heads}) = 0.5, P({Tails}) = 0.5, and P(Omega) = 1."}
{"Major": "Statistics", "Term": "regression analysis", "Explanation": "Regression analysis is a statistical method used to understand and quantify how one outcome variable (the dependent variable) changes when one or more other variables (the independent/predictor variables) change. It fits a model to data, often a straight line (linear regression), that best describes the relationship between variables.\n\nHow it works in plain terms:\n- You choose a target outcome to predict (e.g., house price).\n- You pick one or more predictors (e.g., house size, location).\n- The method finds the line (or curve) that minimizes the differences between the actual observed outcomes and what the model predicts.\n- The line has coefficients: the slope shows how much the outcome changes when a predictor changes, and the intercept is the predicted value when predictors are zero.\n\nCommon uses:\n- Prediction: estimate outcomes for new cases.\n- Understanding: see which predictors are related to the outcome and how strong the relationship is.\n\nNote: correlation does not imply causation, and assumptions about the data matter for valid results."}
{"Major": "Statistics", "Term": "causal study", "Explanation": "Causal study (also called a cause-and-effect study) is research that tries to answer: if we change something (the cause), does another thing change because of it (the effect)? The goal is to show a real cause-and-effect link, not just that two things happen together.\n\nKey ideas:\n- The question is: does X cause Y to change?\n- Researchers try to rule out other explanations that could create a link (confounding factors).\n- Methods that help with this include randomized experiments (randomly assigning people to a treatment or no treatment) and other designs that mimic randomization.\n\nExample: to test if a new drug lowers blood pressure, people are randomly assigned to get the drug or a placebo, and their pressures are compared.\n\nImportant: correlation (two things moving together) does not prove causation. A causal study adds steps to show that changing X leads to a change in Y, often by controlling for other factors and establishing that the cause came before the effect."}
