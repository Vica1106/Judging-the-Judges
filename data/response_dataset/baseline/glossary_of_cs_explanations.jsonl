{"Major": "Computer Science", "Term": "quantum computing", "Explanation": "Quantum computing is a way of computing that uses the strange rules of quantum physics. Instead of classical bits that are either 0 or 1, quantum computers use quantum bits, or qubits, which can be 0, 1, or both at the same time (this is called superposition). Qubits can also be linked together in a property called entanglement, so the state of one qubit can depend on another, even if they are far apart.\n\nBy arranging qubits and applying quantum gates (the operations), a quantum computer can explore many possible answers at once and use interference to emphasize good results and cancel out bad ones. This can make some problems much faster to solve than on regular computers, such as certain kinds of math problems, simulating tiny quantum systems (like molecules), or searching unsorted data more efficiently.\n\nBut quantum computers are very fragile. Qubits easily lose their quantum state (decoherence), so they require special cooling and error correction. Right now they’re mostly experimental devices, but scientists hope to build practical quantum computers for specific tasks in the future."}
{"Major": "Computer Science", "Term": "big O notation", "Explanation": "Big O notation is a math way to describe how the work an algorithm does grows as the input gets bigger. It’s about growth rate, not exact speed on a specific computer.\n\nKey ideas:\n- It usually refers to the worst case (upper bound).\n- We drop constants and less important terms, to focus on the big picture of scalability.\n\nCommon levels (examples of growth rates):\n- O(1): constant time — same work no matter input size (e.g., accessing an item by index in an array).\n- O(log n): grows slowly (e.g., binary search).\n- O(n): grows linearly with input size (e.g., scanning a list).\n- O(n log n): grows a bit faster than linear (e.g., many efficient sorts).\n- O(n^2): grows quadratically (e.g., nested loops over n items).\n\nInterpreting: If one algorithm is O(n) and another is O(n^2), the O(n) one tends to be faster for large inputs, even if the O(n^2) version is quicker on tiny inputs due to constants.\n\nBottom line: Big O helps compare how algorithms scale as data grows, not their exact run times."}
{"Major": "Computer Science", "Term": "semantics", "Explanation": "Semantics in computer science is about meaning—what code, data, or symbols actually do or represent, not just how they are written. It’s the “what happens when you run it” part of a language. This is different from syntax, which is the set of rules for how statements are formed.\n\nExamples:\n- In code, the statement x = x + 1 has the semantics of increasing x by one.\n- A function call f(3) has the semantics of applying f to the value 3 and returning the result.\n- In a database query, the semantics describe which rows are returned or which updates occur.\n\nThere are formal ways to describe semantics, such as:\n- Operational: describe step-by-step how a machine would execute the program.\n- Denotational: map language constructs to mathematical objects representing meaning.\n- Axiomatic: specify what must be true before and after a statement (pre/post conditions).\n\nWhy it matters: semantics let us reason about correctness, predict behavior, and ensure programs and languages interact in well-defined ways."}
{"Major": "Computer Science", "Term": "floating-point arithmetic", "Explanation": "Floating-point arithmetic is how computers store and do math with real numbers (like 3.14, 0.001, or 1e9) using a fixed number of bits. Instead of a full decimal, numbers are stored as a sign, a mantissa (significand), and an exponent. The value is roughly mantissa × base^exponent, and in computers the base is usually 2. For example, a 64-bit float (double) packs 1 sign bit, an exponent, and a 52-bit mantissa.\n\nNumbers are normalized so the leading bit of the mantissa is 1 (when not zero), giving as much precision as the format allows. Because only a finite number of bits are used, most real numbers can’t be represented exactly. Rounding happens when a number is stored, and arithmetic can introduce small errors. There can also be overflow (too large) or underflow (too small). Special values exist, like NaN (not a number) and Infinity; there are also subnormal numbers for very small magnitudes but with less precision.\n\nWhy it matters: rounding errors can accumulate, comparisons can be tricky, and exact equality is rare. But floating-point lets computers perform wide-range, fast real-number math efficiently."}
{"Major": "Computer Science", "Term": "quicksort", "Explanation": "Quicksort is a fast way to sort a list. Here’s the idea in plain terms: pick one item as a pivot. Reorder the other items so that everything smaller than the pivot ends up on its left, and everything larger ends up on its right. The pivot sits between these two groups and is in its final sorted position. Then apply the same process to the left group and to the right group, sorting each part. When both sides are sorted, you join them with the pivot in the middle, giving a fully sorted list.\n\nMany implementations sort in place, meaning they rearrange the existing array without copying it, using a small amount of extra space for the recursion that handles the sublists.\n\nAverage running time is about n log n, which is fast for large lists. In the worst case (if you always pick a bad pivot), it can be n^2, but good pivot choices or random pivots make that rare."}
{"Major": "Computer Science", "Term": "agent-based model (ABM)", "Explanation": "An agent-based model (ABM) is a type of computer simulation used to study complex systems. In an ABM, you create many individual \"agents\"—like people, cars, companies, or animals. Each agent has its own state (age, position, budget, etc.) and simple rules that govern its behavior (move forward, trade with neighbors, follow traffic rules). The agents interact with each other and with a shared environment, and there is no central boss telling everyone what to do.\n\nLittle decisions by many agents can produce big, unpredictable patterns—this is emergence. For example, a traffic ABM might show how small differences in driver behavior can lead to jams, or how a rumor spreads through a social network. ABMs are useful when details at the individual level (heterogeneity, spatial layout, local interactions) matter for the big picture.\n\nLimitations: they can be hard to validate, depend on the chosen rules, and require substantial computing. Example: modeling pedestrians in a mall to study crowd flow and safety."}
{"Major": "Computer Science", "Term": "big data", "Explanation": "Big data means extremely large and complex data sets that are hard to handle with ordinary software. It’s not just about a lot of data; it also involves data that arrives fast and comes in many different forms (text, numbers, pictures, videos) from many sources (phones, websites, sensors, transactions). The goal is to collect and analyze this data to find patterns, trends, or anomalies that help people make better decisions.\n\nKey ideas (the 5 V’s):\n- Volume: huge amounts of data\n- Velocity: data arriving rapidly\n- Variety: many different types and sources\n- Veracity: quality and trustworthiness\n- Value: useful, actionable insights\n\nExamples: social media posts, online shopping logs, weather sensor data, medical records.\n\nUses: personalized recommendations, fraud detection, improving traffic, researching diseases, or optimizing supply chains.\n\nChallenges: storing and cleaning the data, keeping privacy and security, and having enough computing power to analyze it."}
{"Major": "Computer Science", "Term": "class", "Explanation": "In plain language, a class is a blueprint for objects in programming. It describes what data the objects will hold (attributes) and what actions they can perform (methods).\n\n- Attributes: the information stored, like color, size, or name.\n- Methods: the things the object can do, like drive(), speak(), or calculate().\n\nAn object is a concrete item created from a class. Each object has its own values for the attributes, but shares the same set of methods.\n\nExample (conceptual): A Car class might have attributes color, model, and year, and methods honk() and drive(). When you create a specific car, car1, from the Car class, you might set car1.color = \"red\", car1.model = \"Toyota\", car1.year = 2020. You can then call car1.drive() or car1.honk().\n\nWhy it’s useful: classes organize code, let you create many similar things easily, and support reuse and extension through concepts like inheritance."}
{"Major": "Computer Science", "Term": "coding theory", "Explanation": "Coding theory is the study of how to send and store information so it stays accurate even when there’s noise or errors. When you transmit data, bits can get flipped or lost. Coding theory asks: how can we represent the message to make it easy to detect and fix those errors?\n\nThe basic idea is redundancy: add extra bits that don’t carry new information themselves but help check and correct mistakes. An encoder turns a message into a longer codeword; a decoder reads what arrives and tries to guess the original message.\n\nKey ideas:\n- Code distance: how different two valid codewords must be. A bigger distance means more errors can be detected and corrected.\n- Code rate: the fraction of the codeword that actually carries data. Higher rate means more efficiency but less error protection.\n- Types of codes: simple parity checks, Hamming codes; Reed-Solomon codes (used in CDs, DVDs, QR codes); LDPC and Turbo codes (used in modern wireless).\n\nTheory also includes limits on what’s possible, like Shannon’s capacity—the maximum reliable data rate for a noisy channel. Coding theory helps design practical systems that balance speed, storage, and reliability."}
{"Major": "Computer Science", "Term": "computability theory", "Explanation": "Computability theory is the part of computer science and math that asks which problems can be solved by a computer, in principle.\n\n- What it studies: whether there exists a step-by-step procedure (an algorithm) that always gives the correct answer for any valid input.\n- Key ideas: a problem is computable if an algorithm can solve it for all cases; some problems are not computable (no algorithm can solve all cases), even with unlimited time.\n- Models: abstract machines like Turing machines, which help us reason about computation in a simple, precise way. Other models (lambda calculus, formal grammars) are seen as equivalent ways to describe computation.\n- Important results: the halting problem (deciding whether a program stops or runs forever) is undecidable. The Church-Turing thesis suggests that any “effectively calculable” function can be computed by a Turing machine.\n- Decidable vs semi-decidable: some problems have algorithms that always halt with yes/no answers (decidable); some have algorithms that only halt with a correct answer for yes cases but may run forever for no cases (semi-decidable).\n- Role: it reveals the fundamental limits of what computers can ever do, separate from how fast they run."}
