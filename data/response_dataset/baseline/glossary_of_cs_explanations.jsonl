{"Major": "Computer Science", "Term": "quantum computing", "Explanation": "Quantum computing is a way of processing information that uses the strange rules of quantum physics. Traditional computers use bits that are either 0 or 1. Quantum computers use quantum bits, or qubits, which can be 0, 1, or both at the same time (this is called superposition). When qubits are connected (entangled), the state of one can depend on another, even if they’re far apart. By applying quantum gates, we manipulate these states to perform calculations. Because a system with many qubits can represent many possibilities at once, a quantum computer can sometimes solve certain problems much faster than a classical computer. For example, they might factor large numbers or search unsorted data more efficiently. But quantum computers are very delicate: small disturbances cause errors, so error correction is hard. Right now devices are noisy and not yet universally faster for everyday tasks. The big idea is that quantum computing uses superposition and entanglement to tackle some hard problems more efficiently than classical computers, while still facing practical engineering challenges."}
{"Major": "Computer Science", "Term": "big O notation", "Explanation": "Big O notation is a way to describe how the amount of work a computer program does grows as the input gets bigger. It focuses on the worst-case or most significant growth, and it ignores tiny details like constant factors or small tweaks.\n\nKey idea: we care about how the running time or memory use increases as the input size n grows.\n\nCommon examples:\n- O(1): constant time — no matter how big n is (e.g., getting the first item of an array).\n- O(log n): grows slowly (e.g., binary search halves the search space each step).\n- O(n): grows linearly (e.g., checking each item in a list once).\n- O(n^2): grows quadratically (e.g., comparing all pairs of items).\n- O(2^n) or O(n!): grow very fast (intractable for large n).\n\nTip: If a function is 3n + 2, we say it’s O(n) because the n term dominates for large n, and constants don’t matter.\n\nBig O helps compare algorithms to see which scales better as data gets large. There are related notions like Big Theta (tight bound) and Big Omega (lower bound) as well."}
{"Major": "Computer Science", "Term": "semantics", "Explanation": "Semantics in computer science is about meaning—what a piece of code actually does when it runs. Syntax is the exact words, punctuation, and structure you must write. Semantics is the behavior behind those rules: what values are computed, how data changes, and what actions occur.\n\nExample: x = x + 1 has the syntax that looks right, and the semantics that says “increment x by one.” An if statement’s syntax is if (condition) { … } else { … }, and its semantics is: check the condition and run the first block if true, otherwise the second block.\n\nThere are different ways to describe semantics. Operational semantics describes step-by-step how a program executes. Denotational semantics maps a program to its mathematical meaning. Axiomatic semantics states facts about what must be true before and after execution.\n\nSemantics also covers static aspects (like type checking and variable scope) and dynamic aspects (what happens when the program actually runs). Understanding semantics lets us reason about correctness, reason about optimizations safely, and ensure programs behave as intended."}
{"Major": "Computer Science", "Term": "floating-point arithmetic", "Explanation": "Floating-point arithmetic is how computers represent and do math with real numbers (numbers with fractions) using a limited amount of memory. Instead of storing every number exactly, they use a form like scientific notation: a sign, a mantissa (the digits), and an exponent (a power of two). In binary, this lets the computer represent a wide range of values with a fixed number of bits. So numbers are approximate, not exact.\n\nBecause of the finite precision, some decimal fractions (like 0.1) don’t have an exact binary representation, so rounding occurs during storage and every operation. Operations like addition, subtraction, multiplication, and division are therefore approximations too, which can lead to small errors, rounding quirks, or sometimes bigger problems if values get very large, very small, or cancel each other out.\n\nCommon formats (like IEEE 754) standardize how these numbers are stored and how rounding works, as well as special values like infinity, NaN (not a number), and subnormal numbers. Floating-point is essential for speed and range, but developers must be aware of precision limits, rounding errors, and potential overflow/underflow."}
{"Major": "Computer Science", "Term": "quicksort", "Explanation": "Quicksort is a fast way to sort items. It uses a divide-and-conquer idea:\n\n- Pick one item as the pivot.\n- Partition the rest so that everything smaller than the pivot goes to its left and everything bigger goes to its right. The pivot ends up in its final position.\n- Recursively apply the same process to the left part and to the right part until every part is sorted.\n\nKey points:\n- In-place versions can sort in the same array with a few pointers, using little extra memory.\n- Average time is about n log n; worst-case time is n^2 if the pivot is always the smallest or largest element.\n- To avoid worst cases, use a good pivot choice or shuffle first.\n- By default, quicksort is not stable (the relative order of equal items may change).\n\nExample: sorting [3, 6, 8, 2, 10] with a pivot of 6 might partition to [3, 2, 6, 8, 10], then recursively sort [3, 2] and [8, 10] to get [2, 3, 6, 8, 10]."}
{"Major": "Computer Science", "Term": "agent-based model (ABM)", "Explanation": "An agent-based model (ABM) is a type of computer simulation used to study complex systems made of many interacting parts. In an ABM, each part—an agent—follows simple rules. An agent could be a person, a vehicle, a firm, a cell, etc. Agents live in a virtual space and can move, sense their surroundings, and change their behavior based on what they observe and their own state. They interact with other agents and with the environment. Because there is no central control, the overall behavior of the system—patterns, trends, or unexpected outcomes—emerges from many local interactions. ABMs are useful for questions like: how do individual choices affect traffic, disease spread, shopping behavior, or ecological systems?\n\nTypical steps: define agents and rules, create the environment, run the simulation over time, watch what emerges, and adjust rules or parameters to test different scenarios.\n\nPros: intuitive, flexible, captures heterogeneity. Cons: can be computationally heavy and hard to validate. Example: modeling pedestrians forming lanes in a crowd."}
{"Major": "Computer Science", "Term": "big data", "Explanation": "Big data is a term for extremely large and complex sets of information that are hard to analyze with ordinary tools. It includes data from social media, sensors, online transactions, logs, and more.\n\nThe challenge isn’t just size; data also comes in fast (velocity) and in many formats (variety), and it isn’t always perfectly accurate (veracity). People often talk about the three Vs: Volume, Velocity, Variety (and sometimes Veracity).\n\nTo turn big data into useful insights, teams use software that can run on many computers at once (distributed computing) and advanced analytics like machine learning. This helps find patterns, predict trends, optimize operations, personalize services, or detect problems early.\n\nExamples: a site recommending products, a bank spotting fraud, or a city predicting traffic. The goal is to turn raw data into knowledge that supports decisions, while managing privacy, data quality, and cost."}
{"Major": "Computer Science", "Term": "class", "Explanation": "In computer science, a class is a blueprint for a kind of object. It describes what data the object will hold (its attributes or fields) and what actions it can perform (its methods or functions). The class itself doesn’t hold real data—it's a template.\n\nFrom a class, you can create many objects called instances. Each instance follows the same blueprint but can have different data. For example, a class Car might say every car has color and model, and can honk or drive. You could create a red Tesla and a blue Mustang from that same Car class; they share the same structure but have different values.\n\nA constructor is a special method that creates a new object from the class and sets up its initial data. Classes can also inherit from other classes to reuse and extend behavior.\n\nIn short: a class is a reusable template that defines the type of object, what data it stores, and what it can do. An object is a concrete thing created from that template."}
{"Major": "Computer Science", "Term": "coding theory", "Explanation": "Coding theory is the study of how to turn information into a form that can be sent or stored and still be recovered accurately when there’s noise or errors. The idea is to add extra bits (redundancy) to data so a receiver can detect, and often fix, mistakes.\n\nKey ideas:\n- Codes map data to longer codewords. If some bits get flipped, the decoder uses the redundancy to guess the original data.\n- Error-detecting codes (e.g., CRC) can tell when something went wrong.\n- Error-correcting codes (e.g., Hamming, Reed-Solomon) can also repair some errors.\n- The minimum distance between codewords measures how many errors can be corrected; there’s a trade-off between data rate and reliability.\n\nShannon’s theory says there’s a limit to how much information can be sent reliably over a noisy channel, and good codes get close to that limit. Real-world uses include CDs/DVDs, QR codes, data transmission, and storage systems."}
{"Major": "Computer Science", "Term": "computability theory", "Explanation": "Computability theory asks which problems can be solved by an algorithm—a precise, step-by-step procedure a computer could follow. It uses simple abstract models, like Turing machines, to capture what “doing math with a computer” means.\n\nKey ideas:\n- Decidable problems: there exists an algorithm that always finishes and answers yes or no for every input.\n- Undecidable problems: no algorithm can solve all cases. The classic example is the halting problem: can a program determine whether another program will eventually stop or run forever?\n- Reducibility: if solving problem A would let you solve problem B, then A is at least as hard as B; this helps prove undecidability by showing a known hard problem would be solved too.\n- The Church-Turing thesis: any “reasonable” model of computation can simulate any other, so Turing machines capture the intuitive limits of what is computable.\n- Related ideas include recursive functions and formal languages; these frameworks help classify problems as computable or not and study the inherent limits of algorithmic thinking.\n\nBottom line: computability theory explores what can or cannot be solved by any algorithm, not about how fast it runs."}
