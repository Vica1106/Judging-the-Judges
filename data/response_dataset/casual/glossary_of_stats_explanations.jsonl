{"Major": "Statistics", "Term": "mutual independence", "Explanation": "Mutual independence is when several events don’t affect each other at all. If A, B, and C are mutually independent, then the chance that any combination happens is the product of their individual chances.\n\n- So P(A ∩ B ∩ C) = P(A) × P(B) × P(C), and likewise P(A ∩ B) = P(A) × P(B), P(B ∩ C) = P(B) × P(C), etc. This has to hold for every subset of the events.\n\nExample: flip a fair coin three times. Let A be “first flip is heads,” B be “second flip is heads,” and C be “third flip is heads.” Each has probability 1/2. Since flips don’t affect each other, P(A ∩ B ∩ C) = 1/8 = (1/2)^3, and P(A ∩ B) = 1/4 = (1/2)×(1/2), etc. So A, B, and C are mutually independent.\n\nNote: mutual independence is stronger than just pairwise independence—every group must multiply together, not just each pair."}
{"Major": "Statistics", "Term": "statistical inference", "Explanation": "Statistical inference is what you do when you have data from a small group (a sample) and you want to say something about a bigger group (the population). It’s like judging the flavor of an entire soup pot from a single spoonful.\n\nExample: If a school wants the average commute time for all students, they can’t measure everyone. They pick 50 students, find their average commute, and then say something like, “Based on this sample, the real average for all students is probably around 25 minutes, give or take a few minutes.” The “give or take” part is the uncertainty we acknowledge because a sample might not perfectly match the whole population.\n\nSo, inference = use sample data to make a guess about the whole group, plus an idea of how confident or uncertain that guess is."}
{"Major": "Statistics", "Term": "joint distribution", "Explanation": "Joint distribution is basically the recipe for two (or more) things happening together. It tells you how likely each pair of outcomes is.\n\nSimple analogy: imagine you roll two dice. The joint distribution lists the chances of every pair (die 1 shows i, die 2 shows j). Because each die is fair, every pair has 1/36 probability. That full table is the joint distribution for (Die1, Die2).\n\nA quick note:\n- For discrete variables, you use a joint probability mass function P(X = x, Y = y).\n- For continuous variables, it’s a joint probability density f(x, y) (you don’t read a single number, you integrate over a region).\n\nWhy it matters: it also shows how the two variables relate. If knowing X is large makes Y tend to be large too, they’re positively related; if large X goes with small Y, they’re negatively related.\n\nMargins vs. joint: you can get the distribution of X alone by summing over all Y, and similarly for Y. If X and Y are independent, the joint distribution factors into the product of their individual distributions."}
{"Major": "Statistics", "Term": "random variable", "Explanation": "Random variable is just a fancy name for the number you end up with after something random happens.\n\nAnalogy: think of rolling a six-sided die. The random process is the roll. The random variable X is the number you record after the roll. If the die lands on 4, X = 4; if it lands on 1, X = 1, and so on. The dice roll is random, so X can be 1, 2, 3, 4, 5, or 6, each with its own chance.\n\nSo a random variable isn’t the process itself, it’s the numerical outcome you observe from it. You can have many possible values (like 1–6 here) or even non-integer values depending on the situation. We then describe how likely each value is (that’s the “distribution” part) to analyze things and compare outcomes."}
{"Major": "Statistics", "Term": "confidence interval (CI)", "Explanation": "CI stands for confidence interval. It’s a range of numbers you think likely contains the true value you’re estimating (like the true average) based on your sample data.\n\nAnalogy: imagine you’re throwing darts at a target from the same spot. Your darts cluster in a small area. If you drew a circle around that cluster, that circle is like your estimate of where the real bullseye is. If you did this many times, about 95% of those circles would end up containing the bullseye. That’s the idea behind a 95% confidence interval.\n\nSo, a 95% CI means: based on this study, we’re fairly confident the true value lies somewhere in that range. If you repeated the study many times, about 95% of the calculated intervals would cover the true value. It’s about the method and long-run performance, not a guarantee for this single interval.\n\nTip: wider intervals = less precision (more variability or fewer data), narrower intervals = more precision (more data or less variability)."}
{"Major": "Statistics", "Term": "covariance", "Explanation": "Covariance is a simple way to say whether two things tend to move up and down together.\n\nAnalogy: two friends riding bikes side by side. If when one speeds up the other usually does too, they move together and the covariance is positive. If one speeds up while the other slows down, covariance is negative. If there’s no pattern at all, it’s around zero.\n\nExamples:\n- Hours studied and test score: usually go up together, so positive covariance.\n- Temperature and ice cream sales: hotter days often mean more scoops sold, also positive.\n\nA quick note: the size of the covariance matters, but it depends on the units you’re using, so it’s hard to compare across different pairs. That’s why people prefer correlation, which puts the measure on a standard -1 to 1 scale."}
{"Major": "Statistics", "Term": "likelihood function", "Explanation": "Likelihood function\n\n- What it is: A tool that tells you how plausible different values of an unknown parameter are, given what you actually observed. Technically, it’s a function of the parameter(s) with the data fixed: L(theta) = P(data | theta).\n\n- One simple analogy: Think of it like trying to guess the spice level of a soup by tasting it. For each possible spice level theta, you ask “how likely is this taste if the soup really has theta?” The spice level that makes your taste result most likely is your best guess.\n\n- Quick example: Suppose you flip a coin n times and see k heads. The likelihood of a head probability p is L(p) = p^k (1−p)^(n−k). The value of p that maximizes L(p) is p = k/n. This idea is the core of maximum likelihood estimation (MLE).\n\n- Use: It helps estimate parameters and compare models; it’s about plausibility given the data, not the probability of the data itself."}
{"Major": "Statistics", "Term": "probability measure", "Explanation": "Probability measure is the rule that tells you how likely different outcomes are. Think of it as assigning a “slice size” to every event, so you can see how big the chance is.\n\nOne simple analogy: imagine a pie chart of all possible outcomes. Each event gets a slice, and all the slices add up to a whole pie (which is 1). For a fair six-sided die, each single outcome (rolling a 1, 2, 3, 4, 5, or 6) gets a slice of 1/6. The whole space adds up to 1.\n\nTwo quick ideas you’ll use a lot:\n- Probabilities are between 0 and 1. 0 means impossible, 1 means certain.\n- If events can’t happen together (disjoint), their probabilities add. So P(rolling a 4 or a 5) = 1/6 + 1/6 = 2/6.\n\nIn short, a probability measure is the consistent way we quantify “how likely” each event is, and it must sum to 1 over all possible outcomes."}
{"Major": "Statistics", "Term": "regression analysis", "Explanation": "Regression analysis is a simple way to see if one thing can help predict another. Imagine you have a bunch of data points on a graph: for each person, X is something you measure (like hours studied) and Y is the result you care about (like test score). Regression draws a straight line that best fits all those points.\n\nThat line gives you two practical things:\n- The slope: how much Y changes when X goes up by 1 unit. If the slope is 5, each extra hour of study bumps the score by about 5 points.\n- The intercept: what Y would be when X is 0 (the starting point).\n\nYou can use the line to predict Y from a new X (estimated score if someone studies 4 hours). The closeness of the data points to the line tells you how reliable those predictions are.\n\nImportant note: regression shows a relationship, not proof of cause. Other factors might be at play."}
{"Major": "Statistics", "Term": "causal study", "Explanation": "A causal study is basically about figuring out if one thing truly causes another, not just that they happen to occur together.\n\nHow it works: you try to keep everything else the same and only change the thing you think will cause the effect. The classic approach is an experiment: randomly split people or items into two groups. The treatment group gets the thing you think causes the effect; the control group doesn’t. Then you compare outcomes. If the treated group does better, you have evidence that the cause can produce the effect under those conditions.\n\nAnalogy: testing whether salt makes soup taste better. Make two pots exactly alike except one has salt and the other doesn’t. If tasters consistently prefer the salty soup, salt seems to cause better taste (in that situation).\n\nNote: some studies just observe things and look for associations. Those can be informative, but they’re weaker for proving causation because other factors might be at play."}
