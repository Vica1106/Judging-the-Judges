{"Major": "Artificial Intelligence", "Term": "Selective Linear Definite Clause Resolution", "Explanation": "Think of Selective Linear Definite Clause Resolution (SLD) as a simple, rule-based way to answer questions from a small knowledge base.\n\n- Definite clauses: rules like “If X and Y, then Z.” A rule is one head and a body with several subgoals.\n- How it works: you try to prove a query by picking one subgoal at a time, finding a rule whose head matches that subgoal, and replacing the subgoal with the body of that rule. You keep going until you prove all subgoals or you can’t.\n- Selective: you get to pick which subgoal to tackle next (not forced to go left-to-right). The choice can change how fast you find an answer or whether you loop.\n- Linear: you resolve one subgoal per step, so the reasoning path is a single, straight line from the query down to facts.\n\nSimple example:\ngrandparent(X,Z) :- parent(X,Y), parent(Y,Z).\nFacts: parent(alice,bob). parent(bob,carol).\nQuery: grandparent(alice,carol)?\nResolve: match head with query → subgoals: parent(alice,Y), parent(Y,carol).\nPick first: fits with parent(alice,bob), Y=bob → remaining: parent(bob,carol).\nPick second: fits with fact → success.\n\nIn practice, this is how many logic programs (like Prolog) reason about problems."}
{"Major": "Artificial Intelligence", "Term": "Big O notation", "Explanation": "Big O notation is a simple way to say how the amount of work (time) or memory a program needs grows as the input gets bigger.\n\nOne easy analogy: imagine you’re looking for a specific item on a long shelf. If you check each item one by one, the number of checks grows with how many items are there. Double the items, you’ll probably do about twice as many checks. That’s like O(n) — linear growth.\n\nA few common ones:\n- O(1): constant work. No matter how many items, you grab the item at a known spot. Quick jump.\n- O(n): you scan all items once.\n- O(log n): you cut the search space roughly in half each time (like a well-organized index). Grows slowly.\n- O(n^2): you compare many pairs, which gets big fast.\n\nNote: Big O cares about growth rate, not exact seconds, and it ignores constant factors. In AI, it helps us estimate how training or inference time or memory will scale as data or model size grows."}
{"Major": "Artificial Intelligence", "Term": "neural machine translation (NMT)", "Explanation": "Neural machine translation (NMT) is a smart AI way to translate text from one language to another. Think of it like a really good bilingual friend who reads an entire paragraph and then rewrites it in the other language, aiming to keep the meaning, tone, and natural flow.\n\nHow it works, in simple terms: a neural network—just a big math model—learns from tons of example translations. It doesn’t translate word by word; it looks at chunks of text and their context to choose the best phrasing in the target language. Over time it gets better at grammar, style, and tricky expressions.\n\nBenefits: translations tend to sound more natural and coherent, and context helps avoid odd literal mistakes. It’s great for long sentences and whole passages.\n\n caveats: it needs lots of training data and computing power, and it can still mess up idioms or very niche phrases. It might slightly shift meaning in tricky cases.\n\nSo NMT = AI-powered translator that tries to capture meaning and fluency by looking at bigger pieces of text, not just individual words."}
{"Major": "Artificial Intelligence", "Term": "NP-hardness", "Explanation": "NP-hardness is basically the “hardest of the hard” in computer science. NP is the set of problems where, if you’re given a candidate solution, you can check it quickly. NP-hard problems are at least as hard as every problem in NP: for any NP problem, you can transform it into an instance of an NP-hard problem so that solving the NP-hard instance would solve the original problem. In other words, we don’t expect a fast general method (polynomial time) to solve all NP-hard problems. If someone found a quick algorithm for one NP-hard problem, they’d get quick solutions for all NP problems (which most people think won’t happen). Note: NP-complete problems are those that are both in NP and NP-hard. In AI, many real tasks (like certain scheduling or routing problems) are NP-hard, so we rely on approximations, heuristics, or solving special cases. Analogy: if you could crack a single mega-puzzle fast, you’d instantly have a fast way to crack every puzzle of the same kind."}
{"Major": "Artificial Intelligence", "Term": "true quantified Boolean formula", "Explanation": "True quantified Boolean formula is just a fancy way to talk about true/false questions with some “for all” and “there exists” twists.\n\nAnalogy: think of planning a party. The statement says: for every guest (for all), there exists a seat (there exists) such that the guest is happy. The whole sentence is true if you can seat people so that everyone ends up happy no matter who shows up.\n\nA tiny example in plain words: For all x in {0,1}, there exists y in {0,1} such that x OR y is true. If x is 0, you can pick y = 1 to make the OR true. If x is 1, it’s already true no matter what y is. So in every case you can pick a y to make the formula true, hence the whole statement is true.\n\nIn short: a true quantified Boolean formula is a true statement about true/false variables that uses exists and for-all to describe how choices can be made."}
{"Major": "Artificial Intelligence", "Term": "algorithmic probability", "Explanation": "Algorithmic probability is a way to say: how likely is a given string of data if it came from a random computer program?\n\nSimple analogy: imagine a machine that prints whatever a randomly chosen recipe tells it to print. Short recipes are more likely to be picked than long ones, so messages that can be produced by short recipes show up more often.\n\nIn more concrete terms, you look at all programs that output a certain string and give each program a weight that’s bigger for shorter programs (roughly 2 to the minus the program’s length). Add up those weights, and you get the probability of that string. This naturally favors simpler, easier-to-describe outputs — the heart of the “Occam’s razor” idea.\n\nThis idea is formalized in Solomonoff induction and is a powerful theoretical standard for predicting data, but it isn’t computable in practice. In AI, it helps explain why simpler explanations or patterns are often better bets for forecasting future data."}
{"Major": "Artificial Intelligence", "Term": "behavior informatics (BI)", "Explanation": "BI stands for behavior informatics, a field that studies human behavior using data. We collect traces of actions—online clicks, purchases, app usage, wearables—and use AI and stats to find patterns, predict what someone might do next, and improve things like apps or services. It’s not about spying; it’s about turning lots of behavior data into practical insights: what features to build, how to personalize experiences, or where to intervene to help people. Analogy: imagine you’re designing a grocery store to be easy to shop in. By watching many shoppers’ paths—where they go, what they grab, where they slow down—you learn where to place signs, shelves, and discounts. BI uses the same idea with digital traces from many people to guide better products and decisions."}
{"Major": "Artificial Intelligence", "Term": "big data", "Explanation": "Big data is a term for really huge sets of information that are too big for ordinary tools to store or analyze. It comes from lots of places—phones, sensors, apps, websites—and in many forms—texts, numbers, pictures, videos. Because there’s so much of it and it arrives fast, we use special storage and processing to keep it searchable and to pull out useful patterns. Those patterns help AI learn, make predictions, and tailor things to people.\n\nAnalogy: imagine trying to understand what’s happening in an entire city by listening to every message, camera feed, and transaction at once. It’s overwhelming for a single person, but with the right systems you can sort through the flood and find the useful stories.\n\nSo big data is the fuel for AI—the bigger and cleaner the data, the smarter the AI can become."}
{"Major": "Artificial Intelligence", "Term": "convolutional neural network", "Explanation": "Convolutional neural network, or CNN, is a type of AI that does great with images and videos. One simple way to picture it: imagine you have a tiny stamp that looks for a simple pattern (like a line, corner, or dot) and you drag that stamp all over the picture. Wherever the stamp sees that pattern, it leaves a mark on a new, simplified image. That’s one “layer.” You then use more stamps to find bigger patterns in the new image, and you repeat this, stacking layers, until the system can recognize something like a cat or a car.\n\nThe cool part is the same stamp works across the whole image, so the machine learns to spot edges, textures, and shapes without needing special rules for every spot. CNNs are powerful for tasks like tagging photos, guiding self-driving cars, or reading medical images. Want a quick example or a simpler analogy?"}
{"Major": "Artificial Intelligence", "Term": "Darkforest", "Explanation": "Darkforest (or “dark forest”) isn’t a strict AI technical term. It’s more of a cautionary metaphor people use to talk about risk and the unknowns with powerful AI.\n\nIdea behind it: imagine a big forest where you can’t really see what’s out there. If you don’t know what an advanced AI is really capable of or what it might do in new situations, you’d want to move carefully, watchful for surprises, and avoid rushing ahead.\n\nOne simple real-life analogy: walking through a dark forest at night. You can’t see far, you don’t want to shout your plans, and you’re extra careful so you don’t stumble into trouble or scare off potential help.\n\nSo, Darkforest isn’t a feature or tool—it's a way to talk about safety, transparency, and governance when dealing with powerful AI. If you meant a specific project named DarkForest, tell me and I’ll tailor the explanation."}
