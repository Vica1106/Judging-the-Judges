{"Major": "Computer Science", "Term": "quantum computing", "Explanation": "Basic meaning:\nQuantum computing uses quantum bits (qubits) that can be 0, 1, or both at once. By using superposition, entanglement, and interference, quantum computers can process certain problems in fundamentally different and often faster ways than classical computers.\n\nSimple real-world example:\nIn drug discovery, simulating how a drug molecule interacts with a protein is very hard for classical computers. A quantum computer could model these interactions more accurately, potentially predicting effective medicines faster.\n\nWhy it is important:\nIt could revolutionize fields that rely on complex simulations and optimization—chemistry, materials, logistics, climate modeling, and cryptography. It may solve problems that are intractable today, leading to new medicines, better batteries, smarter routes, and more secure communications. Note: it’s early, and not all problems will see big speedups."}
{"Major": "Computer Science", "Term": "big O notation", "Explanation": "- Basic meaning: Big O describes how an algorithm’s running time or memory grows as input size n increases. It ignores constants and minor details, focusing on the worst-case growth (examples: O(1), O(log n), O(n), O(n^2)).\n\n- Simple real-world example: If you search for a book by checking every book until you find it, you might read n books (O(n)). If the shelf is sorted and you can halve the search each time, you only check about log2(n) books (O(log n)).\n\n- Why it’s important: It lets you compare different approaches and predict how they’ll scale with larger data. It helps you choose more efficient algorithms and understand resource needs (time and memory)."}
{"Major": "Computer Science", "Term": "semantics", "Explanation": "- Basic meaning: Semantics is about meaning and behavior. In computer science, it asks what a program actually does when it runs, not just how it looks or is written (that’s syntax).\n\n- Simple real-world example: In a recipe, the instruction “bake for 20 minutes” has a semantic effect: the food is cooked for 20 minutes. In programming, the statement x = x + 1 means the value of x increases by 1—the semantic effect is the change in x’s value.\n\n- Why it’s important: Semantics let us predict and reason about programs, verify they do the right thing, and translate or optimize code safely across languages and machines. Without clear semantics, code could be valid to read but do something unintended."}
{"Major": "Computer Science", "Term": "floating-point arithmetic", "Explanation": "- Basic meaning: Floating-point arithmetic is how computers store and compute real numbers using a fixed number of bits. Numbers are kept in a form similar to scientific notation (sign, a mantissa, and an exponent), allowing a wide range of values with limited precision.\n\n- Simple real-world example: 0.1 and 0.2 cannot be stored exactly in binary. In many computers, 0.1 + 0.2 doesn't equal exactly 0.3; you may get 0.30000000000000004. This is a normal result of finite precision.\n\n- Why it is important: It is used in nearly all computing tasks—graphics, simulations, science, finance—because it lets us handle very big or very small numbers efficiently. The trade-off is rounding errors and potential loss of exactness, which programmers must manage with careful algorithms or, for money, sometimes decimal arithmetic."}
{"Major": "Computer Science", "Term": "quicksort", "Explanation": "- Basic meaning: Quicksort is a sorting method that uses divide-and-conquer. It picks a pivot element, rearranges the list so items smaller than the pivot are on the left and items larger are on the right, then recursively sorts those left and right parts. Finally, it combines them into a sorted order.\n\n- Simple real-world example: Sorting a hand of cards. Pick a pivot card (e.g., 7). Move cards lower than 7 to the left, higher ones to the right. Then apply the same process to the left and right stacks until all cards are in increasing order.\n\n- Why it is important: It is typically very fast on average (about O(n log n) time) and uses little extra memory (in-place). It’s a foundational example of divide-and-conquer and recursion, and is widely used in practice in many libraries. Note: its worst case is O(n^2) if the pivot choices are poor, and it isn’t stable by default."}
{"Major": "Computer Science", "Term": "agent-based model (ABM)", "Explanation": "Agent-based model (ABM)\n\n- Basic meaning: A computer simulation that represents a system with many individual agents. Each agent has simple rules and makes local decisions, and the overall system behavior emerges from their interactions.\n\n- Simple real-world example: People evacuating a building. Each person (agent) moves toward an exit, avoids others, and varies speed. Together, the crowd shows bottlenecks and evacuation times, even though no one is following a global plan.\n\n- Why it’s important: ABMs let us study complex, adaptive systems with many heterogeneous actors and local interactions (traffic, markets, disease spread, ecosystems). They support experiments with different rules or policies and reveal emergent patterns that simple equations might miss."}
{"Major": "Computer Science", "Term": "big data", "Explanation": "Big data\n\n- Basic meaning: Big data means extremely large and complex datasets that are hard to handle with ordinary software. It’s often described by the three Vs: volume (lots of data), velocity (data comes in fast), and variety (different kinds of data such as text, images, numbers).\n\n- Simple real-world example: An online retailer collects millions of daily transactions, product views, searches, reviews, and location data. Analyzing this helps tailor recommendations, detect fraud, and optimize stock and delivery routes.\n\n- Why it’s important: It helps organizations understand patterns, make better decisions, and operate more efficiently at scale. Uses include forecasting demand, personalizing experiences, improving healthcare, and speeding scientific discoveries."}
{"Major": "Computer Science", "Term": "class", "Explanation": "Term: class\n\nIn computer science, a class is a blueprint for creating objects. It defines what data the objects will hold (attributes or fields) and what operations they can perform (methods or functions). A class itself doesn’t hold real data; it describes a type.\n\nReal-world example: a Car class might specify attributes like color, make, model, and speed, and methods like start(), accelerate(), and honk(). You can create many individual cars (objects) from this class—e.g., a red Toyota and a blue Ford—each with its own values but sharing the same behavior.\n\nWhy it matters: classes organize code into reusable, modular building blocks. You can create many similar objects from one class, update behavior in one place, and use features like inheritance to build new classes from existing ones, making programs easier to understand, maintain, and extend."}
{"Major": "Computer Science", "Term": "coding theory", "Explanation": "Coding theory is the study of how to represent information with extra, redundant data so errors can be detected and corrected when it’s transmitted or stored.\n\nReal-world example: QR codes encode data with error-correction so scanners can read the code even if part is damaged or dirty.\n\nWhy it’s important: It keeps communications and storage reliable and efficient—reducing corrupted data, lowering the need for retransmission, and enabling technologies like Wi‑Fi, internet transfer, CDs/DVDs, QR codes, and satellites."}
{"Major": "Computer Science", "Term": "computability theory", "Explanation": "- Basic meaning: Computability theory asks which problems can be solved by a computer using a definite procedure (an algorithm), and which cannot. It uses abstract models (like Turing machines) to distinguish computable tasks from those that are impossible in principle.\n\n- Simple real-world example: The Halting Problem. Given any computer program and input, can we always determine whether the program will eventually stop or run forever? It turns out no general algorithm can decide this for all possible programs, which shows there are limits to what we can automate.\n\n- Why it is important: It reveals the fundamental limits of computation, guiding how we design algorithms and verify software. It helps explain why some questions are unsolvable by machines, influences fields like cryptography and complexity theory, and shapes our understanding of what tasks computers can and cannot perform."}
