{"Major": "Artificial Intelligence", "Term": "Selective Linear Definite Clause Resolution", "Explanation": "Selective Linear Definite Clause Resolution (SLD resolution) is a method used in logic programming to answer questions from a set of facts and rules by a step-by-step deduction.\n\n1) Basic idea: Start with a question (query). Pick one goal at a time, and try to match it with the head of a rule or a fact. If you match, replace the goal with the rule’s body (new subgoals) and continue. You choose one goal (selective) and apply one rule at a time (linear). If you reach an empty goal, you’ve proved the query; if no rule fits, that path fails (backtracking may try alternatives).\n\n2) Real-world example: Rules: grandparent(X,Z) :- parent(X,Y), parent(Y,Z). Facts: parent(alice,bob). parent(bob,carol). Query: is alice a grandparent of carol? Resolve: use the grandparent rule, need parent(alice,Y) and parent(Y,carol). Take Y=bob since both facts hold; hence alice is a grandparent of carol.\n\n3) Why it’s important: It’s the core mechanism behind logic programming languages like Prolog, enabling AI systems to reason with rules and facts, perform automated deduction, planning, and problem solving. It also highlights the trade-off between targeted search and backtracking complexity."}
{"Major": "Artificial Intelligence", "Term": "Big O notation", "Explanation": "Big O notation is a way to describe how an algorithm’s time or space (memory) grows as the input size grows. It focuses on growth trends, not exact times, and ignores small details like constant steps.\n\n- Basic idea: O(n) means time grows in line with the input size, O(log n) grows slowly (doubling input only adds a few steps), O(n^2) grows quickly as input grows.\n\n- Real-world example: Finding a card in a shuffled deck by checking cards one by one is O(n). If the deck is sorted and you can halve the search each time (binary search), you need about log2(n) checks—much faster for large n.\n\n- Why it matters: It helps compare how scalable different algorithms are. As data grows, you can predict performance, choose faster methods, and budget for hardware or time accordingly, which is especially important in AI tasks like data processing and model training."}
{"Major": "Artificial Intelligence", "Term": "neural machine translation (NMT)", "Explanation": "(1) Basic meaning\nNeural Machine Translation (NMT) uses neural networks to translate text from one language to another. Instead of translating word by word, NMT looks at whole sentences, learns how ideas map across languages, and then generates the translated sentence in the target language. It learns from large collections of bilingual text and improves over time.\n\n(2) Simple real-world example\nA traveler uses a translation app to read a menu in Japanese and see English translations. The app processes the sentence and returns fluent phrases like “Grilled fish with rice,” making ordering easier in a foreign restaurant.\n\n(3) Why it is important\nNMT helps people understand information and communicate across languages, enabling travel, education, and global business. It tends to produce more natural, coherent translations than older methods, supports real-time communication, and can run on devices or in the cloud to suit privacy and speed needs."}
{"Major": "Artificial Intelligence", "Term": "NP-hardness", "Explanation": "NP-hardness\n\n- Basic meaning: A problem is NP-hard if every problem whose solution can be checked quickly (NP) can be transformed into it in polynomial time. If you could solve an NP-hard problem fast, you could solve all NP problems fast. Many NP-hard problems are optimization tasks, not just yes/no questions.\n\n- Real-world example: The traveling salesman problem asks for the shortest route that visits each city once and returns home. As the number of cities grows, the number of possible routes explodes, and no fast universal method is known. The decision version “Is there a tour of length ≤ L?” is NP-complete.\n\n- Why it matters: It helps identify problems unlikely to have fast exact solutions, guiding the use of heuristics and approximations. It influences cryptography and many AI challenges, and it highlights the big open question: does P equal NP? NP-hardness maps the boundary between tractable and intractable problems."}
{"Major": "Artificial Intelligence", "Term": "true quantified Boolean formula", "Explanation": "True quantified Boolean formula (QBF) is a way to express a true/false statement that uses “for all” and “there exists” over true/false variables. A QBF has a prefix of quantifiers (like ∀x ∃y …) followed by a Boolean expression φ(x,y,…). The whole statement is true if, for every assignment to the universally quantified variables, there exists an assignment to the existential variables that makes φ true. In short: ∀x ∃y φ(x,y) is true when no matter what x is, you can pick a y that makes φ true.\n\nSimple real-world example:\nA two-player game idea: For every opening move by Player A, there exists a counter-move by Player B that guarantees a win (assuming optimal play). This captures the “for all moves of A, there exists a good response by B” pattern.\n\nWhy it’s important:\nQBF formalizes complex decision problems with alternating choices (adversaries, uncertainty). It underpins AI planning, verification, and reasoning about strategies, and helps us understand the inherent difficulty of such problems."}
{"Major": "Artificial Intelligence", "Term": "algorithmic probability", "Explanation": "Algorithmic probability (also called Solomonoff probability) is a theoretical way to assign a chance to data based on how it could be generated by computer programs.\n\n1) Basic meaning: Take all possible programs that could print a given data string. Shorter programs are more probable because there are many fewer short ones. The probability of the data is the sum of 2^(-length of each program) for all programs that produce it. In short: simpler (shorter) explanations are considered more likely.\n\n2) Simple real-world example: You observe a long string like ABABABABAB… This can be produced by a tiny loop that prints AB repeatedly. A truly random-looking string would need a much longer, messier program. So, under algorithmic probability, the repeating pattern is far more probable than a random sequence of the same length.\n\n3) Why it’s important: It formalizes Occam’s razor in AI—favoring simple explanations helps predictions and learning. It underpins universal priors and inductive inference. It’s uncomputable in general, but motivates practical approaches such as model selection by simplicity and compression-based learning."}
{"Major": "Artificial Intelligence", "Term": "behavior informatics (BI)", "Explanation": "Behavior informatics (BI) is the study and use of data about how people behave to understand patterns, predict actions, and improve systems. It combines data from sensors, apps, and devices with analysis and models to reveal real-world behavior and its drivers.\n\nSimple real-world example: A wearable fitness tracker collects sleep, activity, and heart-rate data. BI analyzes these patterns to identify your daily routine and how it changes over time, then the app personalizes workout reminders and sleep tips accordingly.\n\nWhy it’s important: BI lets AI-powered systems be more responsive and personalized, improving user experiences, health outcomes, and safety. It helps businesses tailor products, optimize services, and make data-driven decisions. It also raises considerations about privacy, consent, and data security."}
{"Major": "Artificial Intelligence", "Term": "big data", "Explanation": "Big data is extremely large, fast-moving, and varied collections of information that traditional tools can’t easily store or analyze. It’s often described by four Vs: volume, velocity, variety, and (sometimes) veracity.\n\nReal-world example: A streaming service collects millions of user signals every second—what you watch, search queries, timestamps, device types, locations, and ratings. The data comes in fast and in many formats. Analyzing it lets the service recommend shows, optimize streaming quality, and detect unusual activity.\n\nWhy it matters: Analyzing big data with AI and analytics leads to smarter decisions, personalized experiences, and more efficient operations. In AI, big data provides the large sets of examples models learn from, making predictions and recommendations more accurate."}
{"Major": "Artificial Intelligence", "Term": "convolutional neural network", "Explanation": "Convolutional neural network (CNN) is a type of AI model designed to understand images and other grid-like data. It uses small filters (kernels) that slide over the image (a process called convolution) to detect simple patterns like edges and corners. Each layer combines these patterns into higher‑level features, so early layers see edges and textures, deeper layers recognize shapes or objects like faces or cars. The model learns these features automatically from many labeled examples; we don’t hand‑craft rules.\n\nSimple real-world example: A photo app that groups pictures by people uses a CNN to recognize patterns in faces or clothing. Self‑driving cars use CNNs to identify stop signs, pedestrians, and traffic lights in real time.\n\nWhy it’s important: CNNs enable powerful, scalable image and video understanding, supporting tasks from automatic photo organization and medical image analysis to autonomous vehicles and quality control in manufacturing. They reduce the need for manual feature engineering and work well with large visual datasets."}
{"Major": "Artificial Intelligence", "Term": "Darkforest", "Explanation": "Darkforest (Dark Forest)\n\n- Basic meaning: A metaphor inspired by Liu Cixin’s sci‑fi idea that in a dangerous universe, civilizations hide themselves and avoid signaling their presence. In AI, it’s used to describe how intelligent agents might stay quiet or concealed to avoid being attacked or copied, since revealing capabilities could invite harm.\n\n- Simple real-world example: Two tech labs develop ultra-advanced AI. If Lab A publicly shows how strong its model is, Lab B might copy it, block it, or take regulatory or competitive actions against Lab A. So both keep capabilities and plans secret, creating a quiet, fast-paced “arms race” rather than open collaboration.\n\n- Why it’s important: It helps explain why pure transparency and open sharing can be risky in AI. The Dark Forest idea highlights the need for thoughtful governance, safety testing, and norms that encourage safe, verifiable collaboration without exposing everyone to malicious actors or copycats. It underlines why managing disclosure, trust, and containment is crucial as AI gets more capable."}
