{"Major": "Computer Science", "Term": "quantum computing", "Explanation": "1) Everyday analogy: Think of a spinning coin that is both heads and tails until you look.\n\n2) Definition: Quantum computing uses qubits (tiny bits of information that can be 0, 1, or both at once) and quantum effects like superposition (being in many states) and entanglement (linked states) to process information differently from ordinary computers.\n\n3) Intuition: With many qubits, you can explore many possibilities at once; interference helps boost the right answers and cancel the rest.\n\n4) Example: 1) Start with 2 qubits. 2) Put them in superposition. 3) Entangle them so their results depend on each other. 4) Measure to read an answer. Repeating makes the correct result more likely than random guessing. This kind approach can speed up hard searches or optimization tasks in AI and science.\n\n5) Takeaway: It could speed up solving certain hard problems, but it’s not a universal speedup yet; current devices are fragile and require specialized algorithms and error correction."}
{"Major": "Computer Science", "Term": "big O notation", "Explanation": "1) Everyday analogy: Imagine a coffee shop line. As more people join, your wait time grows. Big O is the same idea for computer programs: how the work they do grows when the data they handle gets bigger.\n\n2) Definition: Big O notation (growth rate) describes how the running time or memory a program uses increases as the input size n grows. It usually talks about the worst case.\n\n3) Intuition: It helps answer: if you double the amount of data, does the work double (linear), grow a little (log), or explode (quadratic)? It’s about how scalable the method is, not the exact speed on one small task.\n\n4) Example: \n- If you search for an item by checking each element until you find it (or end), you might check about n items for n-sized data, so the time is O(n) (linear). \n- If the data are sorted and you split the search range in half each time, you need about log2(n) checks, so O(log n) time. \n- In AI terms, using a smart index to locate results is often O(1) or O(log n) rather than O(n).\n\n5) Takeaway: Big O helps compare how well algorithms scale. Pitfall: two methods can have the same Big O but run at very different speeds because of constants or real-world factors."}
{"Major": "Computer Science", "Term": "semantics", "Explanation": "1) Everyday analogy: Think of a cooking recipe vs the dish. The recipe is syntax (how it’s written); the dish is semantics (what you end up with).\n\n2) Definition: Semantics is the meaning or behavior of code—the actions it causes and the results it produces when run. It’s the mapping from the language’s symbols to effects like changing variables, producing output, or calling functions. Syntax is the rules for forming valid statements; semantics is what those statements mean.\n\n3) Intuition: Semantics answers what happens when you execute the code. Two programs can look different but have the same effect.\n\n4) Example: Start with x = 3. Then do x = x + 1. Semantics: x becomes 4 (and print(x) would show 4). An equivalent line is x += 1; in most languages it has the same semantics (the same effect).\n\n5) Takeaway: Semantics matter for correctness and cross-language understanding. Pitfall: confusing syntax with semantics; code can look different yet do the same thing, or look the same but behave differently in different languages."}
{"Major": "Computer Science", "Term": "floating-point arithmetic", "Explanation": "1) Everyday analogy: It’s like measuring with a ruler that only has marks every centimeter—numbers are approximated to the nearest mark.\n\n2) Definition: Floating-point arithmetic (how computers store and compute real numbers when the decimal point can move) uses a fixed number of bits to hold the sign, digits, and scale (exponent) of a number.\n\n3) Intuition: It’s like scientific notation in math, but with limited digits. You can handle big or tiny numbers, but you don’t get perfect precision; some digits get rounded away.\n\n4) Example: 0.1 + 0.2 often becomes 0.30000000000000004 in many programs. Why? 0.1 and 0.2 can’t be represented exactly in binary with a fixed number of bits, so the computer stores approximate values and the sum accumulates a tiny rounding error.\n\n5) Takeaway: This matters for numerical accuracy and reproducibility. Common pitfall: assuming exact decimal results or using direct equality checks on floats; instead, use tolerance/epsilon comparisons or appropriate numeric types."}
{"Major": "Computer Science", "Term": "quicksort", "Explanation": "Quicksort\n\n1) Everyday analogy: Imagine sorting a messy pile of cards by picking one card as a reference (pivot). You split the rest into those smaller than the reference and those larger, then do the same splitting inside each smaller and larger pile until everything is ordered.\n\n2) Definition (key terms in plain words): Quicksort is a way to sort a list by: choosing a pivot (a chosen item), dividing the list into items less than the pivot and greater than the pivot (partition), and then recursively sorting the two sublists.\n\n3) Intuition: It’s a fast “divide and conquer” trick—make one quick decision around a pivot, then solve two smaller problems that resemble the original problem.\n\n4) Example:\n- Start with [4, 7, 2, 9, 3], pick pivot 4.\n- Partition into less: [2, 3], pivot 4, greater: [7, 9].\n- Recursively sort [2, 3] (pivot 2 → [2, 3]) and [7, 9] (pivot 7 → [7, 9]).\n- Combine to get [2, 3, 4, 7, 9].\n\n5) Takeaway: It’s efficient on average (roughly logarithmic depth and linear work each level), but can be slow in the worst case if the pivot is poorly chosen; it’s not a stable sort (equal items may not keep their order)."}
{"Major": "Computer Science", "Term": "agent-based model (ABM)", "Explanation": "Think of a crowded park where everyone walks based only on what nearby people are doing—no one plans the whole crowd, but patterns form.\n\nAn agent-based model (ABM) is a computer simulation that uses many agents (individual decision-makers like people or cars) that each follow simple rules and interact with their environment to see what larger patterns emerge.\n\nIntuition: like flocking birds or traffic, simple local choices can create complex global flow.\n\nExample (evacuation):\n- Agents = pedestrians with the goal to reach an exit and to avoid crowding.\n- Rules = move toward the closest exit, slow down when crowded, keep some distance and follow nearby neighbors.\n- Run the sim: trigger an alarm, observe how lanes form and bottlenecks appear at doors; try different doorway placements or widths to see how flow changes.\n\nTakeaway: ABMs help explore how micro-level behavior shapes macro outcomes and test ideas safely before real-world use. Pitfall: rules are simplified and may bias results—always validate with data and test multiple scenarios."}
{"Major": "Computer Science", "Term": "big data", "Explanation": "1) Everyday analogy: Big data is like a fire hose of information. A normal notebook can’t capture, store, or make sense of that much flow.\n\n2) Definition: Big data means extremely large and fast-moving collections of facts (data) about people, things, or events that are too big or messy for traditional software to handle easily.\n\n3) Intuition: As data grows in volume, speed, and variety, you need distributed tools and parallel work to store it and find useful patterns quickly.\n\n4) Example (simple steps): \n- A social platform collects millions of posts every moment.\n- Data are stored across many computers so one machine isn’t overwhelmed.\n- The system analyzes data in parallel to count mentions and spot trends.\n- A live dashboard shows what topics are growing in real time.\n\n5) Takeaway: Big data matters because it unlocks insights that small datasets can’t reveal. Pitfall: more data isn’t automatically better—quality, bias, privacy, and using the right methods are just as important."}
{"Major": "Computer Science", "Term": "class", "Explanation": "1) Everyday analogy: A class is like a cookie cutter or blueprint—one design that lets you make many similar items.\n\n2) Definition (plain): A class is a blueprint (plan) for creating objects (specific things in a program). Key terms: object (a thing made from the blueprint), attribute (a property of the object, e.g., color), method (an action the object can perform, e.g., drive).\n\n3) Intuition: Think of the class as a reusable template. You create many objects from it, each with its own details, just like many cookies cut from the same cutter but with different toppings.\n\n4) Example (mini-illustration): Imagine a Car class that defines attributes like color, model, and year, and methods like drive. Step 1: Create Car1 with color red, model Toyota, year 2020. Step 2: Use Car1.drive() to simulate moving. Step 3: Create Car2 with color blue, model Honda, year 2019. Each car is an object built from the same class but can differ in its attributes.\n\n5) Takeaway: Classes help you organize data and behavior in one reusable blueprint, making big programs easier to manage. Pitfall: overusing classes or mixing up class definitions with individual objects—keep the blueprint separate from its instances."}
{"Major": "Computer Science", "Term": "coding theory", "Explanation": "1) Everyday analogy: Think of sending a fragile item in a box. You add padding (redundant protection) so if some padding gets damaged, the item can still be identified and kept safe.\n\n2) Definition (key terms in plain words):\n- Coding theory: the study of turning messages into longer, structured forms with extra information so errors that occur during sending or storage can be detected and corrected. \n- Code: the rule that turns a message into this padded form.\n- Channel: the path data travel through (phone line, Wi‑Fi, disk) that can introduce errors.\n- Encoder/decoder: the tools that add the redundancy and later recover the original message.\n\n3) Intuition: Adding redundancy is like extra padding around the data. If something gets garbled, the extra information helps you notice the mistake and often fix it, much like spotting a dented box and still knowing what was inside.\n\n4) Example (concrete): Triplicate the bits of a simple message. To send 1,0,1, you encode as 111 000 111. If noise flips some bits during transmission (e.g., becomes 110 010 111), a decoder uses majority vote in each triplet to recover 1,0,1. Simple but powerful.\n\n5) Takeaway: Coding theory matters for reliable communication and storage (CDs, data centers, AI data pipelines). Pitfall: adding too much redundancy wastes bandwidth and may not fix all error patterns; real systems need more sophisticated codes tailored to the noise they expect."}
{"Major": "Computer Science", "Term": "computability theory", "Explanation": "1) Everyday analogy: Imagine a kitchen robot that follows a recipe exactly. computability theory asks which puzzles this robot can solve with a finite recipe (an algorithm) and which have no such recipe.\n\n2) Definition: Computability theory studies what problems can be solved by an algorithm (a precise, finite step-by-step procedure) and which cannot.\n\n3) Intuition: If you can describe a procedure that always finishes and gives the correct answer, the problem is computable. If no general procedure exists, it’s not; this is about the ultimate limits of what machines can do.\n\n4) Example: Sorting a list of numbers is computable—there are many algorithms that always finish. A famous noncomputable problem is the Halting Problem: no algorithm can decide, for every program and input, whether that program will halt. Mini-step: assume such a checker exists; craft a program that says “if you halt, loop forever,” and you get a logical contradiction.\n\n5) Takeaway: Computability theory maps the boundaries of automatic problem-solving. Common pitfall: equating “hard” with “impossible”—computable tasks can be extremely hard or impractical; undecidable problems truly cannot be solved by any algorithm."}
