{"Major": "Artificial Intelligence", "Term": "algorithmic probability", "Explanation": "Algorithmic probability (Solomonoff probability) is a theoretical measure: the chance that a random computer program will print a given string. Shorter (simpler) programs contribute more to the chance, so simpler outputs are considered more probable. It’s noncomputable in general."}
{"Major": "Artificial Intelligence", "Term": "attributional calculus", "Explanation": "Attributional calculus is a formal, rule-based way to reason about objects by their attributes (properties). You encode facts as attributes and rules that link attributes to other facts, then you can infer new conclusions from them (e.g., if something has A and B, it also has C). It’s a method for deriving knowledge from feature-like information."}
{"Major": "Artificial Intelligence", "Term": "statistical relational learning (SRL)", "Explanation": "Statistical Relational Learning (SRL) is AI that learns from data where facts are uncertain and things are related. It uses probabilistic models that combine likelihoods with the relationships between entities (who’s connected to whom) to predict links or properties in networks or knowledge graphs."}
{"Major": "Artificial Intelligence", "Term": "metabolic network reconstruction and simulation", "Explanation": "- Metabolic network reconstruction: building a map of all the chemical reactions in an organism, linking each reaction to the gene/enzyme that drives it, and showing how metabolites flow between reactions.\n- Simulation: using that map in a mathematical model to predict how metabolites move (fluxes) and how the cell behaves under different conditions (growth, product yields, bottlenecks). Often uses methods like flux balance analysis."}
{"Major": "Artificial Intelligence", "Term": "dynamic epistemic logic (DEL)", "Explanation": "Dynamic Epistemic Logic (DEL) is a formal framework that models how multiple agents’ knowledge or beliefs change when events occur or new information is revealed (publicly or privately)."}
{"Major": "Artificial Intelligence", "Term": "neural Turing machine (NTM)", "Explanation": "An NTM is a neural network that has its own external memory (like a tape) and learns to read from and write to it with differentiable operations, so it can learn algorithms and handle tasks needing lots of memory."}
{"Major": "Artificial Intelligence", "Term": "answer set programming (ASP)", "Explanation": "Answer Set Programming (ASP) is a declarative way to solve problems. You encode the problem with logical rules and constraints; a solver searches for all \"answer sets,\" i.e., consistent sets of facts that satisfy the rules. Each answer set represents a valid solution."}
{"Major": "Artificial Intelligence", "Term": "NP-completeness", "Explanation": "NP-complete: the hardest problems in NP. You can quickly check a given solution, but no known fast method to find solutions for all cases. If you could solve one NP-complete problem quickly, you could solve every NP problem quickly (P=NP). Example: SAT (boolean satisfiability)."}
{"Major": "Artificial Intelligence", "Term": "partially observable Markov decision process (POMDP)", "Explanation": "A POMDP is a decision-making framework where the true state of the world is hidden; you take actions, get noisy observations, update your belief about the state, and try to maximize long-term expected reward."}
{"Major": "Artificial Intelligence", "Term": "quantum computing", "Explanation": "Quantum computing is a type of computing that uses quantum bits (qubits), which can be 0 and 1 at the same time. Because of this, quantum computers can explore many possible answers at once, potentially solving some problems much faster than regular computers, though they’re still mostly experimental and good for specific tasks."}
