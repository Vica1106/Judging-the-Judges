{"Major": "Artificial Intelligence", "Term": "Selective Linear Definite Clause Resolution", "Explanation": "- Definition: Selective Linear Definite Clause Resolution is a way computers reason with simple rules (if-then statements with one conclusion) by choosing one goal at a time and replacing it with smaller subgoals, repeating until everything is proven or no rule fits.\n\n- Real-life analogy: It’s like following a recipe: you pick one step to do, look up the single instruction for that step, do it, and then move to the next step until the dish is ready—or you hit a snag.\n\n- Concrete example: Goal: can_drive(john). Rules: can_drive(X) :- has_license(X), sober(X). Facts: has_license(john). sober(john). Start with the goal, replace it with has_license(john) and sober(john); both are true, so can_drive(john) is proven.\n\n- Takeaway: It’s a focused, rule-based way to derive answers—solve one goal at a time, using facts to finish the whole proof."}
{"Major": "Artificial Intelligence", "Term": "Big O notation", "Explanation": "- Definition: Big O notation is a simple way to describe how the running time or memory use of a program grows as the input size increases.\n\n- Real-life analogy: Imagine scanning a guest list: if the list doubles, the number of checks you make roughly doubles.\n\n- Concrete example: If you search for a name by checking every entry until you find a match, the number of checks grows with n, so it's O(n), and for 10 items you might check up to 10, while for 1,000 items you might check up to 1,000 in the worst case.\n\n- Takeaway: Big O helps you compare how solutions scale as data grows, giving a quick feel for whether something will stay fast."}
{"Major": "Artificial Intelligence", "Term": "neural machine translation (NMT)", "Explanation": "- Definition: neural machine translation (NMT) is a computer system that translates text from one language to another by using a neural network that learns from lots of examples.\n\n- Real-life analogy: imagine a student translator who studies thousands of bilingual texts; instead of fixed grammar rules, they learn patterns and guess the best translation for new sentences.\n\n- Concrete example: If you type \"How are you?\" in English, NMT might output \"¿Cómo estás?\" in Spanish by considering context and common phrasing, not just dictionary pairs.\n\n- Takeaway: it matters because translations feel smoother and faster, but it can still misread tricky wording or culture-specific meaning; the core idea is learning from examples to generalize to new sentences."}
{"Major": "Artificial Intelligence", "Term": "NP-hardness", "Explanation": "- Definition: NP-hardness means this problem is at least as hard as the toughest problems whose solutions can be checked quickly; formally, every problem in NP can be transformed into it in polynomial time.\n\n- Real-life analogy: Think of a master lock; if you could crack this one super-hard lock quickly, you could unlock any lock in the building.\n\n- Concrete example: The traveling salesman problem asks for the shortest route to visit many cities and return home; solving that exactly is NP-hard.\n\n- Takeaway: NP-hardness helps explain why some problems stay stubbornly hard to solve exactly as they grow, nudging us toward good-enough or approximate solutions rather than perfect ones."}
{"Major": "Artificial Intelligence", "Term": "true quantified Boolean formula", "Explanation": "- Definition: A true quantified Boolean formula is a statement built from true/false variables with 'for all' and 'exists' that evaluates to true.\n\n- Real-life analogy: It's like a recipe that says: for every guest, there exists a dish that makes them happy.\n\n- Concrete example: Example: for all x in {0,1}, there exists y in {0,1} such that x = y.\n\n- Takeaway: true quantified Boolean formulae mix universal and existential questions, and deciding them is a harder kind of logic that helps in AI reasoning and verification."}
{"Major": "Artificial Intelligence", "Term": "algorithmic probability", "Explanation": "- Definition: algorithmic probability is a way to measure how likely a data pattern is by summing how likely it would be for simple computer programs to print that pattern.\n\n- Real-life analogy: Imagine trying to guess a melody people hum—the simplest, most familiar tunes are more likely to be heard.\n\n- Concrete example: For a string like '0101010101', many short programs could print the repeating pattern, so it has high algorithmic probability, while a random-looking string has low probability.\n\n- Takeaway: So simpler, compressible patterns tend to be more probable, which helps explain why simple structure shows up in data and AI ideas."}
{"Major": "Artificial Intelligence", "Term": "behavior informatics (BI)", "Explanation": "- Definition: behavior informatics (BI) is the study of collecting and analyzing data about how people and things act so we can understand patterns and improve decisions, products, or processes.\n\n- Real-life analogy: Like a fitness tracker for a group or company, it records what people do and shows trends so you can adjust.\n\n- Concrete example: A streaming service uses BI to see what shows you watch and when, then recommends similar titles and times for new releases.\n\n- Takeaway: BI turns behavior data into practical insights that help you save time, improve services, and make smarter choices."}
{"Major": "Artificial Intelligence", "Term": "big data", "Explanation": "- Definition: big data is extremely large and varied information that’s too big to handle with normal tools, used to discover patterns and insights.\n\n- Real-life analogy: It’s like trying to drink from a firehose—the flow of data is huge, so you need filters and machines to sort out the useful parts.\n\n- Concrete example: A streaming service collects millions of viewing events (what you watched, when, on which device) to predict what you’ll want to watch next.\n\n- Takeaway: Why it matters: more data unlocks richer insights than small samples. Practical intuition: with the right tools, big data helps tailor recommendations, optimize systems, and spot trends early. Quick summary: more data means better guidance if you can handle it."}
{"Major": "Artificial Intelligence", "Term": "convolutional neural network", "Explanation": "- Definition: A convolutional neural network is a type of AI model that learns to recognize patterns in images by sliding tiny, simple detectors over the picture and combining what they see.\n\n- Real-life analogy: It’s like stamping a bunch of tiny patterns across a photo—each stamp reads a part of the scene, and then you put the stamps together to see the whole picture.\n\n- Concrete example: If you upload a photo of your cat, the model looks at different parts of the image to spot cat-like features and then decides it’s a cat.\n\n- Takeaway: These nets excel at images because they reuse the same small detectors across the whole picture, making them efficient and good at spotting visual patterns quickly."}
{"Major": "Artificial Intelligence", "Term": "Darkforest", "Explanation": "- Definition: Darkforest is a way to picture how very smart AI might act when it can’t trust other minds, so it stays hidden and careful to avoid trouble.\n\n- Real-life analogy: Imagine walking through a dark forest where you can't tell who’s watching—so you stay quiet, hide your plans, and move only when it’s safe.\n\n- Concrete example: Two rival AI systems in a shared market avoid openly sharing goals; they observe, keep their strategies secret, and act only after they sense no threat.\n\n- Takeaway: in uncertain, competitive AI space, safety and strategic restraint matter—know when to reveal less and watch more."}
